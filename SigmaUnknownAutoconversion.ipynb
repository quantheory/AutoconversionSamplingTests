{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de4c9e5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#User-settings-and-parameters\" data-toc-modified-id=\"User-settings-and-parameters-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>User settings and parameters</a></span></li><li><span><a href=\"#Reading-bin-model-data\" data-toc-modified-id=\"Reading-bin-model-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Reading bin model data</a></span></li><li><span><a href=\"#Shared-utility-code\" data-toc-modified-id=\"Shared-utility-code-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Shared utility code</a></span></li></ul></li><li><span><a href=\"#KK-Autoconversion-Example\" data-toc-modified-id=\"KK-Autoconversion-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>KK Autoconversion Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#User-settings-and-parameters\" data-toc-modified-id=\"User-settings-and-parameters-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>User settings and parameters</a></span></li><li><span><a href=\"#Physical-model-code\" data-toc-modified-id=\"Physical-model-code-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Physical model code</a></span></li><li><span><a href=\"#Mock-observations\" data-toc-modified-id=\"Mock-observations-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Mock observations</a></span></li><li><span><a href=\"#Uncorrelated-errors\" data-toc-modified-id=\"Uncorrelated-errors-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Uncorrelated errors</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-explicit-sigma-parameters\" data-toc-modified-id=\"With-explicit-sigma-parameters-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>With explicit sigma parameters</a></span></li><li><span><a href=\"#With-conjugate-prior-method\" data-toc-modified-id=\"With-conjugate-prior-method-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>With conjugate prior method</a></span></li></ul></li><li><span><a href=\"#Correlated-errors\" data-toc-modified-id=\"Correlated-errors-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Correlated errors</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-explicit-precision-matrix-entries\" data-toc-modified-id=\"With-explicit-precision-matrix-entries-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>With explicit precision matrix entries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distant-starting-point\" data-toc-modified-id=\"Distant-starting-point-2.5.1.1\"><span class=\"toc-item-num\">2.5.1.1&nbsp;&nbsp;</span>Distant starting point</a></span></li><li><span><a href=\"#Close-starting-point\" data-toc-modified-id=\"Close-starting-point-2.5.1.2\"><span class=\"toc-item-num\">2.5.1.2&nbsp;&nbsp;</span>Close starting point</a></span></li></ul></li><li><span><a href=\"#With-conjugate-prior-method\" data-toc-modified-id=\"With-conjugate-prior-method-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>With conjugate prior method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distant-starting-point\" data-toc-modified-id=\"Distant-starting-point-2.5.2.1\"><span class=\"toc-item-num\">2.5.2.1&nbsp;&nbsp;</span>Distant starting point</a></span></li><li><span><a href=\"#Close-starting-point\" data-toc-modified-id=\"Close-starting-point-2.5.2.2\"><span class=\"toc-item-num\">2.5.2.2&nbsp;&nbsp;</span>Close starting point</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Bin-Model-Example\" data-toc-modified-id=\"Bin-Model-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Bin Model Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#User-settings-and-parameters\" data-toc-modified-id=\"User-settings-and-parameters-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>User settings and parameters</a></span></li><li><span><a href=\"#Physical-model-code\" data-toc-modified-id=\"Physical-model-code-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Physical model code</a></span></li><li><span><a href=\"#Mock-observations\" data-toc-modified-id=\"Mock-observations-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Mock observations</a></span></li><li><span><a href=\"#Uncorrelated-errors\" data-toc-modified-id=\"Uncorrelated-errors-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Uncorrelated errors</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-explicit-sigma-parameters\" data-toc-modified-id=\"With-explicit-sigma-parameters-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>With explicit sigma parameters</a></span></li><li><span><a href=\"#With-conjugate-prior-method\" data-toc-modified-id=\"With-conjugate-prior-method-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>With conjugate prior method</a></span></li></ul></li><li><span><a href=\"#Correlated-errors\" data-toc-modified-id=\"Correlated-errors-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Correlated errors</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-explicit-precision-matrix-entries\" data-toc-modified-id=\"With-explicit-precision-matrix-entries-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>With explicit precision matrix entries</a></span></li><li><span><a href=\"#With-conjugate-prior-method\" data-toc-modified-id=\"With-conjugate-prior-method-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>With conjugate prior method</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed914c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0aad1",
   "metadata": {},
   "source": [
    "First import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3abd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.329992Z",
     "start_time": "2022-01-13T15:17:58.418390Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import isqrt\n",
    "import os.path\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gamma, gammaln\n",
    "import scipy.linalg as la\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc4\n",
    "import theano.tensor as tt\n",
    "import theano.tensor.nlinalg as ttla\n",
    "import pymc3 as pm\n",
    "import xarray as xa\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc6b68",
   "metadata": {},
   "source": [
    "Change default figure sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fce218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.334890Z",
     "start_time": "2022-01-13T15:18:01.331737Z"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "matplotlib.rcParams['figure.figsize'] = [6.0, 6.0]\n",
    "az.rcParams['plot.max_subplots'] = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6aece",
   "metadata": {},
   "source": [
    "## User settings and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553b972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:36:06.809980Z",
     "start_time": "2022-01-13T22:36:06.804844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input file from bin model run.\n",
    "TEST_OUTPUT = \"/home/spsantos/CloudBOSS/offline_referencedetail.nc\"\n",
    "\n",
    "# Suffix for output files.\n",
    "SUFFIX = \"_sua\"\n",
    "\n",
    "# Cutoff between rain and cloud bins.\n",
    "CLOUD_RAIN_CUTOFF = 79.37005259840998e-6\n",
    "\n",
    "# Use all bin model runs.\n",
    "CASES = [i for i in range(8)]\n",
    "\n",
    "# Whether to use inference data that was already written to disk.\n",
    "# If set to False, the Monte Carlo code will be run, otherwise we\n",
    "# assume that any appropriately named netCDF files in this directory\n",
    "# were already created from MC runs with appropriate settings.\n",
    "USE_CACHED_IDATA = True\n",
    "# Whether to write cached data in cases where we had to run MC code.\n",
    "WRITE_CACHED_IDATA = True\n",
    "# Directory for reading/writing inference data netCDF files.\n",
    "IDATA_DIR = \"/data/spsantos/MC_output\"\n",
    "\n",
    "# Number of samples drawn in MCMC runs\n",
    "NUM_DRAW = 10000\n",
    "# Number of tuning iterations\n",
    "NUM_TUNE = 5000\n",
    "# Number of MCMC chains\n",
    "CHAINS = 16\n",
    "# Number of cores used to run those chains (should be <= CHAINS)\n",
    "CORES = 16\n",
    "# Seed used for random number generators (set to a constant for reproducibility here)\n",
    "RANDOM_SEED = 56631916\n",
    "\n",
    "# The minimum value used for observations will be MIN_OBS_FAC times the maximum observed\n",
    "# value.\n",
    "MIN_OBS_FAC = 1.e-5\n",
    "# Convert the above value to decibels.\n",
    "min_obs_fac_db = 10. * np.log10(MIN_OBS_FAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764ded7",
   "metadata": {},
   "source": [
    "## Reading bin model data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed3ee9",
   "metadata": {},
   "source": [
    "Read all bin model coordinates, state variables, and process rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f615f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.446463Z",
     "start_time": "2022-01-13T15:18:01.351800Z"
    }
   },
   "outputs": [],
   "source": [
    "offline_data = nc4.Dataset(TEST_OUTPUT, 'r')\n",
    "\n",
    "zs = offline_data['altitude'][:]\n",
    "ts = offline_data['time'][:]\n",
    "moments_cloud = offline_data['cloud_moment'][:]\n",
    "moments_rain = offline_data['rain_moment'][:]\n",
    "\n",
    "nz = len(zs)\n",
    "ntime = len(ts)\n",
    "nmomc = len(moments_cloud)\n",
    "nmomr = len(moments_rain)\n",
    "ncase_total = len(offline_data.dimensions['case'])\n",
    "ncase = len(CASES)\n",
    "\n",
    "dt = offline_data['time'][1] - offline_data['time'][0]\n",
    "\n",
    "theta = offline_data['theta'][:,:,:]\n",
    "rel_hum = offline_data['rel_hum'][:,:,:]\n",
    "pressure = offline_data['pressure'][:,:]\n",
    "\n",
    "cliq_mom = dict()\n",
    "rain_mom = dict()\n",
    "cliq_mom_flux = dict()\n",
    "rain_mom_flux = dict()\n",
    "ccond = dict()\n",
    "cevap = dict()\n",
    "cauto = dict()\n",
    "accr = dict()\n",
    "ccoal = dict()\n",
    "cfall = dict()\n",
    "cond = dict()\n",
    "evap = dict()\n",
    "auto = dict()\n",
    "raccr = dict()\n",
    "coal = dict()\n",
    "fall = dict()\n",
    "for i in range(nmomc):\n",
    "    cliq_mom[moments_cloud[i]] = offline_data['cliq_mom'][:,i,:,:]\n",
    "    cliq_mom_flux[moments_cloud[i]] = offline_data['cliq_mom_flux'][:,i,:]\n",
    "    ccond[moments_cloud[i]] = offline_data['ccond'][:,i,:,:]\n",
    "    cevap[moments_cloud[i]] = offline_data['cevap'][:,i,:,:]\n",
    "    cauto[moments_cloud[i]] = offline_data['cauto'][:,i,:,:]\n",
    "for i in range(nmomr):\n",
    "    rain_mom[moments_rain[i]] = offline_data['rain_mom'][:,i,:,:]\n",
    "    rain_mom_flux[moments_rain[i]] = offline_data['rain_mom_flux'][:,i,:]\n",
    "    cond[moments_rain[i]] = offline_data['cond'][:,i,:,:]\n",
    "    evap[moments_rain[i]] = offline_data['evap'][:,i,:,:]\n",
    "    auto[moments_rain[i]] = offline_data['auto'][:,i,:,:]\n",
    "\n",
    "cliq_path = offline_data['cliq_path'][:,:]\n",
    "rain_path = offline_data['rain_path'][:,:]\n",
    "\n",
    "offline_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c0468",
   "metadata": {},
   "source": [
    "These functions collapse the case, time, and altitude dimensions to leave a single vector with all grid cells and times.\n",
    "\n",
    "The input and output functions are slightly different because the \"input\" variables are output starting at time step 0, while the \"output\" variables calculated from those inputs are recorded on the following time step (with zeros recorded at time step 0). Therefore, we discard the last time step for input variables to the bin model and the first time step for output variables from the bin model to align the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b268a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.452294Z",
     "start_time": "2022-01-13T15:18:01.447879Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_input(x):\n",
    "    per_case = (ntime-1)*nz\n",
    "    x_flat = np.zeros((ncase*per_case,))\n",
    "    for ii in range(ncase):\n",
    "        x_flat[ii*per_case:(ii+1)*per_case] = x[CASES[ii],:-1,:].reshape(per_case)\n",
    "    return x_flat\n",
    "\n",
    "def flatten_output(y):\n",
    "    per_case = (ntime-1)*nz\n",
    "    y_flat = np.zeros((ncase*per_case,))\n",
    "    for ii in range(ncase):\n",
    "        y_flat[ii*per_case:(ii+1)*per_case] = y[CASES[ii],1:,:].reshape(per_case)\n",
    "    return y_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09dd45",
   "metadata": {},
   "source": [
    "Reconstruction of temperature/pressure and thermodynamic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e7bb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.485628Z",
     "start_time": "2022-01-13T15:18:01.453503Z"
    }
   },
   "outputs": [],
   "source": [
    "p_ref = 1.e5\n",
    "rd = 287.15\n",
    "cp = 1005.\n",
    "rhow = 1000.\n",
    "\n",
    "pressure_3d = np.repeat(pressure, ntime, 0).reshape((ncase_total, ntime, nz))\n",
    "temperature = theta * (p_ref / pressure_3d) ** (-rd/cp)\n",
    "rho = pressure_3d / (rd*temperature)\n",
    "rho_flattened = flatten_input(rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c0b00",
   "metadata": {},
   "source": [
    "Because the bin model runs condensation/evaporation before collision-coalescence using sequential splitting, in order to get the inputs to collision-coalescence, we have to apply the effects of condensation/evaporation ourselves offline. This is why the `_pe` (post-evaporation) variables are written out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372155e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.505167Z",
     "start_time": "2022-01-13T15:18:01.486936Z"
    }
   },
   "outputs": [],
   "source": [
    "cliqm0s_pe = np.maximum(flatten_input(cliq_mom[0]) + flatten_output(ccond[0] - cevap[0])*dt, 0.)\n",
    "cliqm3s_pe = np.maximum(flatten_input(cliq_mom[3]) + flatten_output(ccond[3] - cevap[3])*dt, 0.)\n",
    "\n",
    "rainm0s_pe = np.maximum(flatten_input(rain_mom[0]) + flatten_output(cond[0] - evap[0])*dt, 0.)\n",
    "rainm3s_pe = np.maximum(flatten_input(rain_mom[3]) + flatten_output(cond[3] - evap[3])*dt, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae413cd9",
   "metadata": {},
   "source": [
    "Here we also construct the `cm0`/`cm3` masks. These masks filter out points where the number concentration is below $10^{-2}$/kg or the mass mixing ratio is below $10^{-15}$ kg/kg respectively, so that we only bother fitting to data points where there is some discernible amount of cloud. The `rm0`/`rm3` masks apply the same limiters to rain number and mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c75b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.509843Z",
     "start_time": "2022-01-13T15:18:01.506594Z"
    }
   },
   "outputs": [],
   "source": [
    "cm0_mask_pe = cliqm0s_pe > 1.e-2\n",
    "cm3_mask_pe = cliqm3s_pe > 1.e-15 / (np.pi / 6. * rhow)\n",
    "\n",
    "rm0_mask_pe = rainm0s_pe > 1.e-2\n",
    "rm3_mask_pe = rainm3s_pe > 1.e-15 / (np.pi / 6. * rhow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa6658",
   "metadata": {},
   "source": [
    "\"Normalized\" versions of cloud and rain moments. Normalization in this case just means division by number concentration, not full non-dimensionalization. A normalized version of rain $M_0$ is also written, which is just the ratio of rain number concentration to cloud number concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d772f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.522464Z",
     "start_time": "2022-01-13T15:18:01.510984Z"
    }
   },
   "outputs": [],
   "source": [
    "cm3norms_pe = np.where(cm0_mask_pe, cliqm3s_pe / np.maximum(cliqm0s_pe, 1.e-2), 0.)\n",
    "rm3norms_pe = np.where(rm0_mask_pe, rainm3s_pe / np.maximum(rainm0s_pe, 1.e-2), 0.)\n",
    "rm0cnorms_pe = np.where(cm0_mask_pe, rainm0s_pe / np.maximum(cliqm0s_pe, 1.e-2), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d526c",
   "metadata": {},
   "source": [
    "Flatten collision-coalescence rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2f510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.534937Z",
     "start_time": "2022-01-13T15:18:01.524604Z"
    }
   },
   "outputs": [],
   "source": [
    "cauto0s = flatten_output(cauto[0])\n",
    "auto0s = flatten_output(auto[0])\n",
    "cauto3s = flatten_output(cauto[3])\n",
    "auto3s = flatten_output(auto[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20816993",
   "metadata": {},
   "source": [
    "## Shared utility code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e84ef",
   "metadata": {},
   "source": [
    "Log-probability averager that attempts to avoid overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b781d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.539945Z",
     "start_time": "2022-01-13T15:18:01.536079Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_mean_exp(array):\n",
    "    \"\"\"Returns the logarithm of the mean of exp(array).\n",
    "\n",
    "    This function is mainly used to calculate the logarithm of the mean of a set of probabilities,\n",
    "    given the logarithms of those probabilities. Using `np.log(np.mean(np.exp(array)))` naively\n",
    "    will usually result in overflow, so this function was written to avoid that.\n",
    "    \"\"\"\n",
    "    # Shift the array so that the maximum element is 0.\n",
    "    scale_fac = array.max()\n",
    "    log_mean = np.log(np.mean(np.exp(array - scale_fac)))\n",
    "    # Shift back.\n",
    "    return log_mean + scale_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff9f96",
   "metadata": {},
   "source": [
    "Multivariate gamma function's natural log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99677d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.548316Z",
     "start_time": "2022-01-13T15:18:01.541226Z"
    }
   },
   "outputs": [],
   "source": [
    "def multigammaln(m, x):\n",
    "    \"\"\"Returns logarithm of the multivariate gamma function of x for m dimensions.\"\"\"\n",
    "    pi_fac = 0.25 * m * (m-1.) * np.log(np.pi)\n",
    "    gammas_fac = sum([gammaln(x + 0.5 * (1.-j)) for j in range(m)])\n",
    "    return pi_fac + gammas_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9677031",
   "metadata": {},
   "source": [
    "Convert lower-triangular matrix (e.g. from Cholesky decomposition) to a vector of its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0203cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.559585Z",
     "start_time": "2022-01-13T15:18:01.549824Z"
    }
   },
   "outputs": [],
   "source": [
    "def triangular(n):\n",
    "    \"\"\"Returns the n-th triangular number.\"\"\"\n",
    "    return n*(n+1) // 2\n",
    "\n",
    "def lower_tri_to_elements(tri):\n",
    "    \"\"\"Given a matrix, return an array of the elements on or below the diagonal.\n",
    "\n",
    "    For certain matrix classes, this is a completed description of the matrix.\n",
    "    (E.g. lower triangular, symmetric, or skew-symmetric matrices.)\n",
    "    \"\"\"\n",
    "    n = tri.shape[0]\n",
    "    elems = np.zeros((triangular(n),))\n",
    "    tri_numbers = np.array([triangular(i) for i in range(n+1)])\n",
    "    for i in range(n):\n",
    "        elems[tri_numbers[i]:tri_numbers[i+1]] = tri[i,:i+1]\n",
    "    return elems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923cd9a",
   "metadata": {},
   "source": [
    "Code used to go the opposite direction, from a list of elements to a full matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866bf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.573332Z",
     "start_time": "2022-01-13T15:18:01.560800Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_triangular_size(n):\n",
    "    \"\"\"Finds the matrix size corresponding to a number of nonzero elements.\n",
    "\n",
    "    In essence, this is an inverse for the function mapping integers to triangular numbers,\n",
    "    which throws an error if the input is not triangular.\n",
    "    \"\"\"\n",
    "    size = isqrt(2*n)\n",
    "    assert (size*(size+1) // 2) == n, \\\n",
    "        \"number of triangular matrix entries is not a triangular number\"\n",
    "    return size\n",
    "\n",
    "def theano_from_lower_tri_elements(elems):\n",
    "    \"\"\"Construct a Theano representation of a lower triangular matrix given nonzero elements.\"\"\"\n",
    "    size = check_triangular_size(elems.dsize)\n",
    "    tri_numbers = [triangular(i) for i in range(size+1)]\n",
    "    rows = []\n",
    "    for i in range(size):\n",
    "        row = [elems[i] for i in range(tri_numbers[i], tri_numbers[i+1])]\n",
    "        row = row + ((size - (i + 1)) * [0.])\n",
    "        rows.append(tt.stack(row))\n",
    "    return tt.stack(rows)\n",
    "\n",
    "def theano_from_cholesky_elements(elems):\n",
    "    \"\"\"Construct a Theano representation of a matrix given its Cholesky factor's elements.\"\"\"\n",
    "    chol = theano_from_lower_tri_elements(elems)\n",
    "    return tt.dot(chol, tt.transpose(chol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d63c38",
   "metadata": {},
   "source": [
    "Define a variable using a logarithmic prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef78e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.586088Z",
     "start_time": "2022-01-13T15:18:01.574476Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_logarithmic_prior(name):\n",
    "    \"\"\"Defines a variable with the given name having the improper logarithmic prior.\n",
    "\n",
    "    Must be called from within a PyMC3 model's context.\n",
    "    \"\"\"\n",
    "    var_log = pm.Flat(name+'_log')\n",
    "    return pm.Deterministic(name, tt.exp(var_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300752e4",
   "metadata": {},
   "source": [
    "Uncorrelated error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21403ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.613476Z",
     "start_time": "2022-01-13T15:18:01.587401Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_uncorrelated_error(model_var, obs, output_name, sigma_name):\n",
    "    \"\"\"Set up error for a model output assuming no correlation with other errors.\n",
    "\n",
    "    Must be called from within a PyMC3 model's context.\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for this output.\n",
    "    output_name - Name of model output variable.\n",
    "    sigma_name - Name of sigma variable, which will be added with the logarithmic prior.\n",
    "\n",
    "    Returns:\n",
    "    Model output variable\n",
    "    \"\"\"\n",
    "    sigma = define_logarithmic_prior(sigma_name)\n",
    "    return pm.Normal(output_name, mu=model_var, sigma=sigma, observed=obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c7ee4",
   "metadata": {},
   "source": [
    "Routine to add all uncorrelated errors for a list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6c554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:39:24.865065Z",
     "start_time": "2022-01-13T20:39:24.853815Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_uncorrelated_error_multiple(model_var, obs, var_names):\n",
    "    \"\"\"Set up uncorrelated error model for multiple observation types.\n",
    "\n",
    "    Must be called from within a PyMC3 model's context.\n",
    "    Array arguments are assumed to be 2-dimensional matrices, with the first dimension\n",
    "    being the number of samples and the second of length at least len(var_names).\n",
    "\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for this output.\n",
    "    var_names - Names to use for variable definitions. Sigma parameters will be named\n",
    "                'sigma_' + var_names[i] and output variables will be named\n",
    "                'output_' + var_names[i] for the i-th variable.\n",
    "    \"\"\"\n",
    "    for i in range(len(var_names)):\n",
    "        name = var_names[i]\n",
    "        define_uncorrelated_error(model_var[:,i], obs[:,i], 'output_'+name, 'sigma_'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f68a7",
   "metadata": {},
   "source": [
    "Uncorrelated error model used for conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a2e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.630283Z",
     "start_time": "2022-01-13T15:18:01.623116Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_like_uncorrelated_conjp(n_obs, sum_sq_err):\n",
    "    \"\"\"Log-likelihood formula for uncorrelated error with conjugate prior method.\"\"\"\n",
    "    return -0.5 * n_obs * tt.log(sum_sq_err)\n",
    "\n",
    "def define_uncorrelated_error_conjp(model_var, obs, output_name, sum_sq_err_name):\n",
    "    \"\"\"Set up uncorrelated error for a model output when using conjugate prior method.\n",
    "\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for this output.\n",
    "    output_name - Name of model output variable.\n",
    "    sum_sq_err_name - Name of sum-of-squared-errors variable to be recorded.\n",
    "\n",
    "    Returns:\n",
    "    Model likelihood variable\n",
    "    \"\"\"\n",
    "    sum_sq_err = pm.Deterministic(sum_sq_err_name, tt.sum((obs - model_var)**2))\n",
    "    return pm.DensityDist(output_name, log_like_uncorrelated_conjp,\n",
    "                          observed={'n_obs': len(obs), 'sum_sq_err': sum_sq_err})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de9266",
   "metadata": {},
   "source": [
    "Routine to add all uncorrelated errors for autoconversion specifically, for conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827cc1cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:41:57.896582Z",
     "start_time": "2022-01-13T20:41:57.888922Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_uncorrelated_error_conjp_multiple(model_var, obs, var_names):\n",
    "    \"\"\"Set up uncorrelated conjugate prior error model for multiple observation types.\n",
    "\n",
    "    Must be called from within a PyMC3 model's context.\n",
    "    Array arguments are assumed to be 2-dimensional matrices, with the first dimension\n",
    "    being the number of samples and the second of length at least len(var_names).\n",
    "\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for this output.\n",
    "    var_names - Names to use for variable definitions. Sums of squared errors will be named\n",
    "                'sum_sq_err_' + var_names[i] and log-likelihood variables will be named\n",
    "                'log_like_' + var_names[i] for the i-th variable.\n",
    "    \"\"\"\n",
    "    for i in range(len(var_names)):\n",
    "        name = var_names[i]\n",
    "        define_uncorrelated_error_conjp(model_var[:,i], obs[:,i], 'log_like_'+name, 'sum_sq_err_'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287fb5b",
   "metadata": {},
   "source": [
    "Define a matrix variable using the independent Jeffreys prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ceb15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.660700Z",
     "start_time": "2022-01-13T15:18:01.652490Z"
    }
   },
   "outputs": [],
   "source": [
    "def independent_jeffreys_prior_log_like(elems):\n",
    "    \"\"\"Log-likelihood for elements of the Cholesky decomposition of a matrix.\n",
    "\n",
    "    This distribution is equivalent to the improper prior proportional to\n",
    "    the determinant of the matrix to the power -(size+1)/2. In terms of the\n",
    "    Cholesky decomposition matrix elements, if c_n is the n-th diagonal element,\n",
    "    then the likelihood is proportional to c_n^-n.\n",
    "    \"\"\"\n",
    "    size = check_triangular_size(elems.dsize)\n",
    "    diag_idxs = [triangular(i+1) - 1 for i in range(size)]\n",
    "    positive = np.array(True)\n",
    "    log_like = 0.\n",
    "    for i in range(size):\n",
    "        diag = elems[diag_idxs[i]]\n",
    "        positive = positive & (diag > 0.)\n",
    "        log_like = log_like - (i+1)*tt.log(diag)\n",
    "    # If matrix is not positive-definite, reject, otherwise use calculated log-likelihood.\n",
    "    return tt.switch(positive, log_like, -np.inf)\n",
    "\n",
    "def independent_jeffreys_prior(name, chol_name, size, chol_testvals=None):\n",
    "    \"\"\"Create variables for a matrix and its Cholesky factor with an improper prior.\n",
    "\n",
    "    The prior used is the independent Jeffreys prior for covariance/precision of a\n",
    "    multivariate normal distribution. (This prior happens to be the same for both\n",
    "    the covariance matrix and the precision matrix.)\n",
    "\n",
    "    Arguments:\n",
    "    name - Name of matrix variable to add.\n",
    "    chol_name - Name of the variable to add for Cholesky factor elements.\n",
    "    size - Size of the matrix.\n",
    "    chol_testvals (optional) - Location of test point to start MCMC at for Cholesky elements.\n",
    "                               If not provided, the default is the identity matrix.\n",
    "\n",
    "    Returns:\n",
    "    (mat, chol_elems) - mat is matrix variable, chol_elems is corresponding Cholesky elements.\n",
    "    \"\"\"\n",
    "    dsize = triangular(size)\n",
    "    if chol_testvals is None:\n",
    "        diag_idxs = [triangular(i+1) - 1 for i in range(size)]\n",
    "        chol_testvals = np.zeros(dsize)\n",
    "        for i in range(size):\n",
    "            chol_testvals[diag_idxs[i]] = 1.\n",
    "    else:\n",
    "        assert len(chol_testvals) == dsize, \"Input cholesky test values are the wrong size\"\n",
    "    chol_elems = pm.DensityDist(chol_name, independent_jeffreys_prior_log_like, shape=(dsize,),\n",
    "                                testval=chol_testvals)\n",
    "    mat = pm.Deterministic(name, theano_from_cholesky_elements(chol_elems))\n",
    "    return (mat, chol_elems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd28679",
   "metadata": {},
   "source": [
    "Correlated error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935d9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.671695Z",
     "start_time": "2022-01-13T15:18:01.661914Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_correlated_error(model_var, obs, name, omega_name, omega_chol_name,\n",
    "                            chol_testvals=None):\n",
    "    \"\"\"Set up error for a correlated set of model outputs.\n",
    "\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for these outputs.\n",
    "    name - Name of model output variable.\n",
    "    omega_name - Name of precision matrix variable.\n",
    "    omega_chol_name - Name of variable for precision matrix Cholesky factor elements.\n",
    "    chol_testvals (optional) - Location of test point to start MCMC at for cholesky elements.\n",
    "                               If not provided, the default is the identity matrix.\n",
    "    Returns:\n",
    "    Model output variable\n",
    "    \"\"\"\n",
    "    size = obs.shape[1]\n",
    "    omega, chol_elems = independent_jeffreys_prior(omega_name, omega_chol_name, size,\n",
    "                                                   chol_testvals=chol_testvals)\n",
    "    return pm.MvNormal(name, mu=model_var, tau=omega, observed=obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89034e",
   "metadata": {},
   "source": [
    "Correlated error model used for conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00706ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.685193Z",
     "start_time": "2022-01-13T15:18:01.673005Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_like_correlated_conjp(n_obs, sum_sq_err):\n",
    "    \"\"\"Log-likelihood formula for correlated error with conjugate prior method.\"\"\"\n",
    "    return -0.5 * n_obs * tt.log(ttla.Det()(sum_sq_err))\n",
    "\n",
    "def define_correlated_error_conjp(model_var, obs, output_name, sum_sq_err_name):\n",
    "    \"\"\"Set up correlated error for a model output when using conjugate prior method.\n",
    "\n",
    "    Arguments:\n",
    "    model_var - Prediction from physical model.\n",
    "    obs - Observed value for these outputs.\n",
    "    output_name - Name of model output variable.\n",
    "    sum_sq_err_name - Name of sum-of-squared-errors variable to be recorded.\n",
    "    \"\"\"\n",
    "    rates_error = obs - model_var\n",
    "    sum_sq_err = pm.Deterministic(sum_sq_err_name, tt.dot(rates_error.T, rates_error))\n",
    "    return pm.DensityDist(output_name, log_like_correlated_conjp,\n",
    "                          observed={'n_obs': obs.shape[0], 'sum_sq_err': sum_sq_err})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b636a",
   "metadata": {},
   "source": [
    "Set some defaults for Metropolis sampler. Several of the options are directly set as parameters above (e.g. `NUM_DRAW`). Additionally, we set the following:\n",
    "\n",
    " - `return_inferencedata=True`: Return arviz object that can be readily converted to netCDF instead of old style of PyMC3 trace.\n",
    " - `log_likelihood=False`: Set to avoid crashes from excessive memory usage due to large number of observations.\n",
    " - `density_dist_obs=False`: Set to avoid a bug that crashes PyMC3 when the model uses `DensityDist` and `return_inferencedata=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734a139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.694144Z",
     "start_time": "2022-01-13T15:18:01.686558Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_metropolis(chains=CHAINS):\n",
    "    \"\"\"Sample parameters for current model using a Metropolis sampler.\n",
    "\n",
    "    Returns an InferenceData object.\n",
    "    \"\"\"\n",
    "    return pm.sample(NUM_DRAW, tune=NUM_TUNE, step=pm.Metropolis(),\n",
    "                     return_inferencedata=True, chains=chains, random_seed=RANDOM_SEED,\n",
    "                     cores=CORES,\n",
    "                     idata_kwargs={'log_likelihood': False, 'density_dist_obs': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d0b62",
   "metadata": {},
   "source": [
    "Set some defaults for NUTS sampler. In addition to the parameters set for the Metropolis sampler, we set:\n",
    "\n",
    "- `init=adapt_diag`: Set to disable \"jitter\" in the initial value, which can cause crashes. (E.g. when the initial value is perturbed to a region so far outside the high-probability region that certain gradient-related calculations overflow.)\n",
    "- `target_accept`: Tuning parameter passed through to NUTS sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ed24c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.704536Z",
     "start_time": "2022-01-13T15:18:01.695443Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_NUTS(chains=CHAINS, target_accept=0.8):\n",
    "    \"\"\"Sample parameters for current model using the NUTS sampler.\n",
    "\n",
    "    Arguments:\n",
    "    target_accept (optional) - Target acceptance ratio used for tuning the Hamiltonian solver (default 0.8).\n",
    "\n",
    "    Returns an InferenceData object.\n",
    "    \"\"\"\n",
    "    return pm.sample(NUM_DRAW, tune=NUM_TUNE,\n",
    "                     return_inferencedata=True, chains=chains, random_seed=RANDOM_SEED,\n",
    "                     cores=CORES, init='adapt_diag',\n",
    "                     idata_kwargs={'log_likelihood': False, 'density_dist_obs': False},\n",
    "                     target_accept=target_accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93dd0c2",
   "metadata": {},
   "source": [
    "Draw samples from set of gamma distributions with the same shape parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a085afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.713585Z",
     "start_time": "2022-01-13T15:18:01.705655Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_from_shared_shape_gammas(alpha, betas):\n",
    "    \"\"\"Draw one sample each from a set of gamma distributions with the same shape parameter.\n",
    "\n",
    "    Arguments:\n",
    "    alpha - Shared shape parameter.\n",
    "    betas - Scale parameters for the distributions.\n",
    "\n",
    "    Returns a vector of drawn values.\n",
    "    \"\"\"\n",
    "    y = pm.Gamma.dist(alpha=alpha, beta=1.)\n",
    "    num = len(betas)\n",
    "    draws = y.random(size=num)\n",
    "    return draws / betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ceab4",
   "metadata": {},
   "source": [
    "Draw samples of sigma after MCMC has completed using conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff6c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.721437Z",
     "start_time": "2022-01-13T15:18:01.715193Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_sigma_samples(idata, n_obs, sum_sq_err_name, sigma_name):\n",
    "    \"\"\"For an MCMC run using conjugate prior likelihood for uncorrelated error, add samples of sigma.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    n_obs - Number of observations producing the sum_sq_err values.\n",
    "    sum_sq_err_name - Name of variable storing sum of squared error for each data point.\n",
    "    sigma_name - Name of variable where sigma samples will be stored in idata.posterior.\n",
    "    \"\"\"\n",
    "    sum_sq_err = idata.posterior[sum_sq_err_name].data\n",
    "    tau = np.reshape(draw_from_shared_shape_gammas(0.5*n_obs, 0.5 * sum_sq_err.flatten()),\n",
    "                     sum_sq_err.shape)\n",
    "    sigma = 1./np.sqrt(tau)\n",
    "    idata.posterior = idata.posterior.assign({\n",
    "        sigma_name: xa.Variable(('chain', 'draw'), sigma),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b591a",
   "metadata": {},
   "source": [
    "Call `add_sigma_samples` for multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf4015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:45:56.926922Z",
     "start_time": "2022-01-13T20:45:56.920025Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_sigma_samples_multiple(idata, n_obs, var_names):\n",
    "    \"\"\"For MCMC run using conjugate prior method and uncorrelated error, add samples of sigma.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    n_obs - Number of observations producing the sum_sq_err values.\n",
    "    var_names - Names to use for variable definitions. Sums of squared errors must be named\n",
    "                'sum_sq_err_' + var_names[i] in idata, and sigma variables will be named\n",
    "                'log_like_' + var_names[i], for the i-th variable.\n",
    "    \"\"\"\n",
    "    for i in range(len(var_names)):\n",
    "        name = var_names[i]\n",
    "        add_sigma_samples(idata, n_obs, 'sum_sq_err_'+name, 'sigma_'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cd185",
   "metadata": {},
   "source": [
    "Draw samples of omega after MCMC has completed using conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f8fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.744579Z",
     "start_time": "2022-01-13T15:18:01.736546Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_from_shared_shape_Wishart(nu, Vs):\n",
    "    \"\"\"Draw one sample each from a set of Wishart distributions with the same shape parameter.\n",
    "\n",
    "    This function depends on the fact that drawing from a Wishart distribution with scale\n",
    "    factor V is the same as drawing a matrix X from a Wishart distribution with the identity\n",
    "    matrix as a scale factor, then multiplying by the Cholesky factors of V. That is, if L\n",
    "    is a Cholesky factor of V, then L X L^T can be used as a Wishart sample.\n",
    "\n",
    "    Arguments:\n",
    "    nu - Shared shape parameter.\n",
    "    Vs - Scale parameters for the distributions.\n",
    "         Assumed to be 3-dimensional array of shape (num_samples, size, size).\n",
    "\n",
    "    Returns:\n",
    "    Array of samples of the same shape as Vs.\n",
    "    \"\"\"\n",
    "    y = pm.Wishart.dist(nu=nu, V=np.eye(Vs.shape[1]))\n",
    "    num = Vs.shape[0]\n",
    "    omegas = y.random(size=num)\n",
    "    for i in range(num):\n",
    "        V_chol = la.cholesky(Vs[i,:,:], lower=True)\n",
    "        omegas[i,:,:] = np.matmul(np.matmul(V_chol, omegas[i,:,:]), V_chol.T)\n",
    "    return omegas\n",
    "\n",
    "def add_omega_samples(idata, n_obs, sum_sq_err_name, omega_name, omega_chol_name):\n",
    "    \"\"\"For an MCMC run using conjugate prior likelihood for correlated error, add precision matrix samples.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    n_obs - Number of observations producing the sum_sq_err values.\n",
    "    sum_sq_err_name - Name of variable storing sum of squared error for each data point.\n",
    "    omega_name - Name of variable where precision matrix samples will be stored in idata.posterior.\n",
    "    omega_chol_name - Name of variable where omega Cholesky factor samples will be stored in idata.posterior.\n",
    "    \"\"\"\n",
    "    sum_sq_err = idata.posterior[sum_sq_err_name].data\n",
    "    chains = sum_sq_err.shape[0]\n",
    "    num_samples = sum_sq_err.shape[1]\n",
    "    mat_size = sum_sq_err.shape[2]\n",
    "    Vs = np.zeros((chains*num_samples, mat_size, mat_size))\n",
    "    for i in range(chains):\n",
    "        for j in range(num_samples):\n",
    "            Vs[i*num_samples+j,:,:] = la.inv(sum_sq_err[i,j,:,:])\n",
    "    omegas = np.reshape(draw_from_shared_shape_Wishart(n_obs, Vs), sum_sq_err.shape)\n",
    "    num_chol = triangular(mat_size)\n",
    "    omega_chol_elems = np.zeros((chains, num_samples, num_chol))\n",
    "    for i in range(chains):\n",
    "        for j in range(num_samples):\n",
    "            omega_chol_elems[i,j,:] = lower_tri_to_elements(la.cholesky(omegas[i,j,:,:], lower=True))\n",
    "    idata.posterior = idata.posterior.assign_coords({\n",
    "        omega_chol_name+'_dim_0': [i for i in range(num_chol)],\n",
    "    })\n",
    "    idata.posterior = idata.posterior.assign({\n",
    "        omega_name: xa.Variable(('chain', 'draw', sum_sq_err_name+'_dim_0', sum_sq_err_name+'_dim_1'), omegas),\n",
    "        omega_chol_name: xa.Variable(('chain', 'draw', omega_chol_name+'_dim_0'), omega_chol_elems)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fe4ee",
   "metadata": {},
   "source": [
    "Add information from a dictionary of timing data to an InferenceData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a3fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.755501Z",
     "start_time": "2022-01-13T15:18:01.745838Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_timer_data(idata, timers):\n",
    "    \"\"\"Add timing information to InferenceData object.\n",
    "\n",
    "    Arguments:\n",
    "    idata - The InferenceData object.\n",
    "    timers - A dictionary associating timer names (strings) to times taken (floats).\n",
    "             Timer names must be no more than 64 characters.\n",
    "    \"\"\"\n",
    "    # Some logic to ensure that 'Total' is always the first named timer, if present.\n",
    "    timer_names = [name for name in timers.keys() if name != 'Total']\n",
    "    if 'Total' in timers.keys():\n",
    "        timer_names = ['Total'] + timer_names\n",
    "    timer_name_array = np.array(timer_names, dtype='<U64')\n",
    "    timer_name_variable = xa.Variable(('num_timer'), timer_name_array)\n",
    "    timer_time_variable = xa.Variable(('num_timer'), [timers[name] for name in timer_names])\n",
    "    idata.sample_stats = idata.sample_stats.assign({\n",
    "        'timer_name': timer_name_variable,\n",
    "        'timer_time': timer_time_variable,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af609b",
   "metadata": {},
   "source": [
    "Overall driver for running MCMC code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f0bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.765547Z",
     "start_time": "2022-01-13T15:18:01.756779Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_mcmc(obs, physical_model, error_model, mcmc_sample, post_mcmc_sample=None,\n",
    "             physical_kwargs=None, error_kwargs=None, mcmc_kwargs=None, post_kwargs=None,\n",
    "             file_prefix=None):\n",
    "    \"\"\"Driver method for MCMC runs.\n",
    "\n",
    "    This function must be called within a PyMC3 model's context.\n",
    "\n",
    "    Arguments:\n",
    "    obs - Observations corresponding to model outputs.\n",
    "    physical_model - Function that defines the physical model, and returns an array of all\n",
    "                     physical model outputs.\n",
    "    error_model - Function that takes the rates from the physical model and observations\n",
    "                  as the first two arguments, and completes the overall statistical model\n",
    "                  by defining an error model.\n",
    "    mcmc_sample - Function that runs the MCMC sampler.\n",
    "    post_mcmc_sample (optional) - Function that reconstructs samples of other quantities\n",
    "                                  not included in the MCMC sampling.\n",
    "    physical_kwargs (optional) - Keyword arguments to be passed to physical_model.\n",
    "    error_kwargs (optional) - Keyword arguments to be passed to error_model.\n",
    "    mcmc_kwargs (optional) - Keyword arguments to be passed to mcmc_sample.\n",
    "    post_kwargs (optional) - Keyword arguments to be passed to post_mcmc_sample.\n",
    "    file_prefix (optional) - File prefix to use for reading/writing cache file.\n",
    "                             The actual file name will be '{}{}.nc'.format(file_prefix, SUFFIX)\n",
    "\n",
    "    Returns:\n",
    "    An InferenceData object containing the samples from mcmc_sample and post_mcmc_sample,\n",
    "    as well as timing data.\n",
    "    \"\"\"\n",
    "    if file_prefix is not None:\n",
    "        file_name = '{}{}.nc'.format(file_prefix, SUFFIX)\n",
    "        file_name = os.path.join(IDATA_DIR, file_name)\n",
    "        # If cache exists and we can use it, read in idata and skip all calculations.\n",
    "        if USE_CACHED_IDATA and os.path.isfile(file_name):\n",
    "            return az.from_netcdf(file_name)\n",
    "    start_total = perf_counter()\n",
    "    timers = {}\n",
    "    if physical_kwargs is None:\n",
    "        physical_kwargs = {}\n",
    "    if error_kwargs is None:\n",
    "        error_kwargs = {}\n",
    "    if mcmc_kwargs is None:\n",
    "        mcmc_kwargs = {}\n",
    "    if post_kwargs is None:\n",
    "        post_kwargs = {}\n",
    "    # Set up statistical model.\n",
    "    rates_model = physical_model(**physical_kwargs)\n",
    "    error_model(rates_model, obs, **error_kwargs)\n",
    "    # Find and print MAP as a diagnostic.\n",
    "    start_MAP = perf_counter()\n",
    "    maxpost = pm.find_MAP()\n",
    "    print(maxpost)\n",
    "    timers['find_MAP'] = perf_counter() - start_MAP\n",
    "    # Sample with MCMC and post-MCMC samplers.\n",
    "    start_mcmc = perf_counter()\n",
    "    idata = mcmc_sample(**mcmc_kwargs)\n",
    "    timers['mcmc_sample'] = perf_counter() - start_mcmc\n",
    "    if post_mcmc_sample is not None:\n",
    "        start_post = perf_counter()\n",
    "        n_obs = obs.shape[0]\n",
    "        post_mcmc_sample(idata, n_obs, **post_kwargs)\n",
    "        timers['post_mcmc_sample'] = perf_counter() - start_post\n",
    "    timers['Total'] = perf_counter() - start_total\n",
    "    add_timer_data(idata, timers)\n",
    "    # If caching is enabled, write out the idata to cache file.\n",
    "    if file_prefix is not None and WRITE_CACHED_IDATA:\n",
    "        idata.to_netcdf(file_name)\n",
    "    return idata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbdc841",
   "metadata": {},
   "source": [
    "Function to print summary statistics after sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794b076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.780237Z",
     "start_time": "2022-01-13T15:18:01.767221Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_mean_std(name, array):\n",
    "    \"\"\"Print mean and standard devation of values in an array.\"\"\"\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    print(\"Mean (std. dev.) of {} is {} ({}).\".format(name, mean, std))\n",
    "\n",
    "def print_summary_statistics(idata, parameter_names):\n",
    "    \"\"\"Print summary diagnostics for parameters after MCMC run.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    parameter_names - Names of parameters to print diagnostics for.\n",
    "\n",
    "    Currently prints mean, standard deviation, and relative effective sample size\n",
    "    (i.e. effective sample size divided by actual sample size) for each variable.\n",
    "    If divergence data is available and any chains had divergences, the number of\n",
    "    divergences will also be printed for that chain.\n",
    "\n",
    "    For array parameters, diagnostics will be printed for each element in row-major\n",
    "    order, subscripting each element with its index in a flattened array.\n",
    "    \"\"\"\n",
    "    esses = az.ess(idata, relative=True)\n",
    "    sub_param_names = []\n",
    "    param_data = {}\n",
    "    ess_dict = {}\n",
    "    for name in parameter_names:\n",
    "        param_shape = idata.posterior[name].shape\n",
    "        if len(param_shape) == 2:\n",
    "            sub_param_names.append(name)\n",
    "            param_data[name] = idata.posterior[name].data\n",
    "            ess_dict[name] = esses[name].data\n",
    "        else:\n",
    "            num_sub_params = np.prod(param_shape[2:])\n",
    "            data_flattened = np.reshape(idata.posterior[name].data,\n",
    "                                        (param_shape[0], param_shape[1], num_sub_params))\n",
    "            for i in range(num_sub_params):\n",
    "                sub_name = name + '_{}'.format(i)\n",
    "                sub_param_names.append(sub_name)\n",
    "                param_data[sub_name] = data_flattened[:,:,i]\n",
    "                ess_dict[sub_name] = esses[name].data[i]\n",
    "    for name in sub_param_names:\n",
    "        print_mean_std(name, param_data[name])\n",
    "    for name in sub_param_names:\n",
    "        print(\"Relative ESS of {} is {}.\".format(name, ess_dict[name]))\n",
    "    chains = len(idata.posterior.chain)\n",
    "    if 'diverging' in idata.sample_stats.variables:\n",
    "        for i in range(chains):\n",
    "            divergences = np.count_nonzero(idata.sample_stats.diverging[i,:])\n",
    "            if divergences != 0:\n",
    "                print(\"{} divergences were encountered in chain {}.\".format(divergences, i))\n",
    "    if 'timer_name' in idata.sample_stats.variables:\n",
    "        for i in range(len(idata.sample_stats.num_timer)):\n",
    "            name = idata.sample_stats.timer_name.data[i]\n",
    "            time = idata.sample_stats.timer_time.data[i]\n",
    "            print(\"Time taken for '{}' was {} seconds.\".format(name, time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b13d6b",
   "metadata": {},
   "source": [
    "Preferred way to plot traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445a5e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.791832Z",
     "start_time": "2022-01-13T15:18:01.781371Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_trace(idata, parameter_names, kind=None):\n",
    "    \"\"\"Plot a trace with arviz.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    parameter_names - Used as var_names in arviz's plot_trace.\n",
    "    kind (optional) - Used as kind in arviz's plot_trace, default value is 'rank_vlines'.\n",
    "    \"\"\"\n",
    "    if kind is None:\n",
    "        kind = 'rank_vlines'\n",
    "    az.plot_trace(idata, var_names=parameter_names, chain_prop='color', kind=kind, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7489fc",
   "metadata": {},
   "source": [
    "Preferred settings for pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c50b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:01.803594Z",
     "start_time": "2022-01-13T15:18:01.793013Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pair(idata, parameter_names, divergences=True):\n",
    "    \"\"\"Pair plot showing joint marginals of named parameters.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object.\n",
    "    parameter_names - Names of parameters to plot.\n",
    "    divergences (optional) - Whether to plot divergence data, if available. Defaults to True.\n",
    "    \"\"\"\n",
    "    az.plot_pair(idata, var_names=parameter_names, kind=['kde'], marginals=True,\n",
    "                 divergences=divergences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbe70c",
   "metadata": {},
   "source": [
    "# KK Autoconversion Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a52d63",
   "metadata": {},
   "source": [
    "## User settings and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83591518",
   "metadata": {},
   "source": [
    "Number of points for MCMC integration and evaluation of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4f82f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:12.120304Z",
     "start_time": "2022-01-13T20:51:12.116410Z"
    }
   },
   "outputs": [],
   "source": [
    "NFIT_KK = 10000\n",
    "NEVAL_KK = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19e390",
   "metadata": {},
   "source": [
    "Location and width of priors for physical model parameters. In general, the prior means are not especially close to the true values, but the width of the prior distributions are quite large. We use a width equal to 2 for the exponents, which is multiplied by 50 db to get a sigma of 100 db for `a_db`. The width of the mean mass distributions is 30 db, i.e. the mean diameter is allowed to vary by up to an order of magnitude.\n",
    "\n",
    "To explain the factor of 50 db, we note that we expect the autoconversion rate to scale quadratically with the number of cloud particles, e.g. if the concentration of particles triples, the number of collisions should increase by a factor of nine. This relationship implies that $b_q + b_n \\approx 2$, and that most of the variation in plausible autoconversion schemes should be in $b_q - b_n$, i.e. the dependence on $q_c/n_c$, which is on the order of $-50$db. (This scaling relationship is not really true for the KK scheme in particular, where $b_q + b_n = 0.68$, but we find that as a rule of thumb it is reasonable to use a prior for `a_db` that is around 50 db times the exponent priors, especially in cases like this where the prior is not very strict and so does not really impact the result much.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad57681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:13.247768Z",
     "start_time": "2022-01-13T20:51:13.240868Z"
    }
   },
   "outputs": [],
   "source": [
    "MU_A_DB = 30.\n",
    "SIGMA_A_DB = 100.\n",
    "MU_BQ = 3.\n",
    "SIGMA_BQ = 2.\n",
    "MU_BN = -1.\n",
    "SIGMA_BN = 2.\n",
    "MU_MEAN_MC_DB = 10. * np.log10(rhow * np.pi / 6. * (CLOUD_RAIN_CUTOFF)**3.)\n",
    "SIGMA_MEAN_MC_DB = 30.\n",
    "MU_MEAN_MR_DB = 10. * np.log10(rhow * np.pi / 6. * (CLOUD_RAIN_CUTOFF)**3.)\n",
    "SIGMA_MEAN_MR_DB = 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc99b46",
   "metadata": {},
   "source": [
    "## Physical model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4b1f7",
   "metadata": {},
   "source": [
    "Define power law model for KK-like autoconversion predictions, in decibels. Note that since this is defined only in terms of the operators `+` and `*`, it should work on any combination of scalars, arrays, and theano variables, as long as the corresponding dimensions are compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca468d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:13.937685Z",
     "start_time": "2022-01-13T20:51:13.932875Z"
    }
   },
   "outputs": [],
   "source": [
    "def two_moment_power_law(a_db, b1, b2, m1_db, m2_db):\n",
    "    \"\"\"Calculate autoconversion rate in decibels from model parameters and two input moments.\n",
    "\n",
    "    Arguments:\n",
    "    a_db - Power law coefficient in decibels\n",
    "    b1, b2 - Power law exponents\n",
    "    m1_db, m2_db - Corresponding moment values in decibels\n",
    "\n",
    "    Returns:\n",
    "    Power law output in decibels\n",
    "    \"\"\"\n",
    "    return a_db + b1 * m1_db + b2 * m2_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa816c95",
   "metadata": {},
   "source": [
    "Set priors for physical model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114abcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:14.629335Z",
     "start_time": "2022-01-13T20:51:14.619314Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_priors_kk(testvals=None):\n",
    "    \"\"\"Define priors for a_db, bq, bn, mean_mc_db, and mean_mr_db.\n",
    "\n",
    "    Must be called in from a context with an active PyMC3 model.\n",
    "    Arguments:\n",
    "    testvals (optional) - Used to define the integration starting points for MCMC.\n",
    "                          If not provided, the prior means will be used for these values.\n",
    "                          If provided, 'testvals' must contain values for all five variables.\n",
    "\n",
    "    Returns:\n",
    "    (a_db, bq, bn, mean_mc_db, mean_mr_db)\n",
    "    \"\"\"\n",
    "    if testvals is None:\n",
    "        testvals = [MU_A_DB, MU_BQ, MU_BN, MU_MEAN_MC_DB, MU_MEAN_MR_DB]\n",
    "    a_db = pm.Normal('a_db', mu=MU_A_DB, sigma=SIGMA_A_DB, testval=testvals[0])\n",
    "    bq = pm.Normal('bq', mu=MU_BQ, sigma=SIGMA_BQ, testval=testvals[1])\n",
    "    bn = pm.Normal('bn', mu=MU_BN, sigma=SIGMA_BN, testval=testvals[2])\n",
    "    mean_mc_db = pm.Normal('mean_mc_db', mu=MU_MEAN_MC_DB, sigma=SIGMA_MEAN_MC_DB, testval=testvals[3])\n",
    "    mean_mr_db = pm.Normal('mean_mr_db', mu=MU_MEAN_MR_DB, sigma=SIGMA_MEAN_MR_DB, testval=testvals[4])\n",
    "    return (a_db, bq, bn, mean_mc_db, mean_mr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853ea2c",
   "metadata": {},
   "source": [
    "Evaluate physical model given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75310d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:15.544985Z",
     "start_time": "2022-01-13T20:51:15.533309Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                          qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db, disable_theano=False):\n",
    "    \"\"\"Physical model for KK given a set of parameters and data to run the model on.\n",
    "\n",
    "    Arguments:\n",
    "    a_db, bq, bn - Power law parameters.\n",
    "    mean_mc_db, mean_mr_db - Mean masses of cloud and rain, respectively.\n",
    "    qc_db - Mass mixing ratios (kg/kg) in decibels.\n",
    "    nc_db - Number concentrations (#/cm^3) in decibels.\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "    disable_theano (optional) - Disable theano and work directly with floats. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    A Theano variable representing a 2D array where the first dimension is the dimension of any\n",
    "    vector input variables, and the second dimension is 3 (for outputting q, nc, and nr rates,\n",
    "    in that order). If all inputs are scalar, the variable will be 1D. Note that the `eval` method\n",
    "    of a Theano variable can be used to produce floating-point output, assuming that necessary\n",
    "    values are provided to fully evaluate the expression defining the variable.\n",
    "\n",
    "    If disable_theano is True, qc_db must be a 1D array, and a float will be input assuming that\n",
    "    all inputs are floats or ndarrays.\n",
    "    \"\"\"\n",
    "    # Rates from physical model\n",
    "    rate_q_model = two_moment_power_law(a_db, bq, bn, qc_db, nc_db)\n",
    "    rate_nc_model = rate_q_model - mean_mc_db\n",
    "    rate_nr_model = rate_q_model - mean_mr_db\n",
    "    if disable_theano:\n",
    "        output = np.zeros((len(qc_db), 3))\n",
    "        output[:,0] = np.maximum(rate_q_model, min_q_auto_db)\n",
    "        output[:,1] = np.maximum(rate_nc_model, min_nc_auto_db)\n",
    "        output[:,2] = np.maximum(rate_nr_model, min_nr_auto_db)\n",
    "        return output\n",
    "    else:\n",
    "        # Limit physical model outputs.\n",
    "        rate_q_model = tt.maximum(rate_q_model, min_q_auto_db)\n",
    "        rate_nc_model = tt.maximum(rate_nc_model, min_nc_auto_db)\n",
    "        rate_nr_model = tt.maximum(rate_nr_model, min_nr_auto_db)\n",
    "        return tt.stack((rate_q_model, rate_nc_model, rate_nr_model), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5be4a0",
   "metadata": {},
   "source": [
    "Physical model setup within PyMC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c015e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:15.941117Z",
     "start_time": "2022-01-13T20:51:15.934247Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_physical_model_kk(qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db, testvals=None):\n",
    "    \"\"\"Define physical model predicting autoconversion rate as a power law in two cloud moments.\n",
    "\n",
    "    Arguments:\n",
    "    qc_db - Mass mixing ratio (kg/kg, converted to decibels).\n",
    "    nc_db - Number concentration (#/cm^3, converted to decibels).\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "    testvals (optional) - Starting points for MCMC integration, passed to define_priors_kk.\n",
    "\n",
    "    Returns:\n",
    "    A 2D array with rows containing mass, cloud number, and rain number rates, respectively.\n",
    "    \"\"\"\n",
    "    # Define physical model parameters\n",
    "    a_db, bq, bn, mean_mc_db, mean_mr_db = define_priors_kk(testvals)\n",
    "    # Rates from physical model\n",
    "    return run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                                 qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca0fdd",
   "metadata": {},
   "source": [
    "Posterior predictive probability for uncorrelated errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5aa797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:16.332152Z",
     "start_time": "2022-01-13T20:51:16.312954Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_uncorr_kk(idata, obs, qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations assuming uncorrelated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    qc_db - Cloud mass mixing ratios corresponding to observations (kg/kg, converted to decibels).\n",
    "    nc_db - Cloud number concentrations corresponding to observations (#/cm^3, converted to decibels).\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = -0.5 * n_obs * 3 * np.log(2. * np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            bq = idata.posterior.bq.data[i,j]\n",
    "            bn = idata.posterior.bn.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                                          qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db,\n",
    "                                          disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            sum_sq_err = np.sum((obs - rates)**2, axis=0)\n",
    "            sigmas = np.zeros((3,))\n",
    "            sigmas[0] = idata.posterior.sigma_q.data[i,j]\n",
    "            sigmas[1] = idata.posterior.sigma_nc.data[i,j]\n",
    "            sigmas[2] = idata.posterior.sigma_nr.data[i,j]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + \\\n",
    "                np.sum(-0.5 * sum_sq_err / sigmas**2 - n_obs * np.log(sigmas))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba6ea2",
   "metadata": {},
   "source": [
    "Alternative posterior predictive probability density calculation based on conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2223b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:16.783851Z",
     "start_time": "2022-01-13T20:51:16.766795Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_uncorr_conjp_kk(idata, n_obs_orig, obs, qc_db, nc_db,\n",
    "                                         min_q_auto_db, min_nc_auto_db, min_nr_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations assuming uncorrelated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    n_obs_orig - Number of observations used to create original data set (may be vector or scalar).\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    qc_db - Cloud mass mixing ratios corresponding to observations (kg/kg, converted to decibels).\n",
    "    nc_db - Cloud number concentrations corresponding to observations (#/cm^3, converted to decibels).\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Allow n_obs_orig to be a scalar by casting it to a vector here if necessary.\n",
    "    if np.isscalar(n_obs_orig):\n",
    "        n_obs_orig = np.repeat(n_obs_orig, 3)\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = np.sum(gammaln(0.5*(n_obs_orig+n_obs))\n",
    "                            -gammaln(0.5*(n_obs_orig))\n",
    "                            -0.5*n_obs*np.log(np.pi))\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            bq = idata.posterior.bq.data[i,j]\n",
    "            bn = idata.posterior.bn.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                                          qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db,\n",
    "                                          disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            sum_sq_err = np.sum((obs - rates)**2, axis=0)\n",
    "            sum_sq_err_orig = np.zeros((3,))\n",
    "            sum_sq_err_orig[0] = idata.posterior.sum_sq_err_q.data[i,j]\n",
    "            sum_sq_err_orig[1] = idata.posterior.sum_sq_err_nc.data[i,j]\n",
    "            sum_sq_err_orig[2] = idata.posterior.sum_sq_err_nr.data[i,j]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + 0.5 * \\\n",
    "                np.sum(n_obs_orig * np.log(sum_sq_err_orig) -\n",
    "                       (n_obs_orig+n_obs)*np.log(sum_sq_err_orig + sum_sq_err))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a0a1f",
   "metadata": {},
   "source": [
    "Posterior predictive probability for correlated errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5609372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:17.193859Z",
     "start_time": "2022-01-13T20:51:17.179397Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_corr_kk(idata, obs, qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations with correlated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    qc_db - Cloud mass mixing ratios corresponding to observations (kg/kg, converted to decibels).\n",
    "    nc_db - Cloud number concentrations corresponding to observations (#/cm^3, converted to decibels).\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = -0.5 * n_obs * 3 * np.log(2. * np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            bq = idata.posterior.bq.data[i,j]\n",
    "            bn = idata.posterior.bn.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                                          qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db,\n",
    "                                          disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            error = obs - rates\n",
    "            sum_sq_err = np.matmul(error.T, error)\n",
    "            omega = idata.posterior.omega.data[i,j,:,:]\n",
    "            log_pppd_sample[i,j] = prob_prefactor - \\\n",
    "                0.5 * np.trace(np.matmul(sum_sq_err, omega)) + \\\n",
    "                0.5 * n_obs * np.log(la.det(omega))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de02975",
   "metadata": {},
   "source": [
    "Alternative posterior predictive probability density calculation based on conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c81456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:17.596956Z",
     "start_time": "2022-01-13T20:51:17.581587Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_corr_conjp_kk(idata, n_obs_orig, obs, qc_db, nc_db,\n",
    "                                         min_q_auto_db, min_nc_auto_db, min_nr_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations with correlated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    n_obs_orig - Number of observations used to create original data set.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    qc_db - Cloud mass mixing ratios corresponding to observations (kg/kg, converted to decibels).\n",
    "    nc_db - Cloud number concentrations corresponding to observations (#/cm^3, converted to decibels).\n",
    "    min_q_auto_db - Minimum value of mass mixing ratio autoconversion rate that can be predicted.\n",
    "    min_nc_auto_db - Minimum value of cloud number autoconversion rate that can be predicted.\n",
    "    min_nr_auto_db - Minimum value of rain number autoconversion rate that can be predicted.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = multigammaln(3, 0.5*(n_obs + n_obs_orig)) - \\\n",
    "        multigammaln(3, 0.5*(n_obs_orig)) - 0.5 * n_obs * 3 * np.log(np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            bq = idata.posterior.bq.data[i,j]\n",
    "            bn = idata.posterior.bn.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_kk(a_db, bq, bn, mean_mc_db, mean_mr_db,\n",
    "                                          qc_db, nc_db, min_q_auto_db, min_nc_auto_db, min_nr_auto_db,\n",
    "                                          disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            error = obs - rates\n",
    "            sum_sq_err = np.matmul(error.T, error)\n",
    "            sum_sq_err_orig = idata.posterior.sum_sq_err.data[i,j,:,:]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + \\\n",
    "                0.5 * n_obs_orig * np.log(la.det(sum_sq_err_orig)) - \\\n",
    "                0.5 * (n_obs_orig+n_obs)*np.log(la.det(sum_sq_err_orig + sum_sq_err))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bc072",
   "metadata": {},
   "source": [
    "## Mock observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038098a",
   "metadata": {},
   "source": [
    "Show the total number of data points from input data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51865c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:19.069141Z",
     "start_time": "2022-01-13T20:51:19.064019Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size = len(cm0_mask_pe)\n",
    "print(data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d1df3",
   "metadata": {},
   "source": [
    "We filter out the data points where there's too little cloud present to get a slightly smaller data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022185f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:20.153605Z",
     "start_time": "2022-01-13T20:51:20.146225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_mask = np.logical_and(cm0_mask_pe, cm3_mask_pe)\n",
    "np.count_nonzero(draw_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4614b",
   "metadata": {},
   "source": [
    "Set up random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3d1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:21.059113Z",
     "start_time": "2022-01-13T20:51:21.054246Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00937789",
   "metadata": {},
   "source": [
    "Fairly simple way of sampling data points. We also convert cloud third moment to mass mixing ratio and zeroth moment to number concentration in $\\#/\\text{cm}^3$ in the process.\n",
    "\n",
    "If values are cached, skip the sampling and read in from file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600f260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:22.646823Z",
     "start_time": "2022-01-13T20:51:22.485968Z"
    }
   },
   "outputs": [],
   "source": [
    "# number concentration of cloud in #/cm^3\n",
    "nc_fit = np.zeros((NFIT_KK,))\n",
    "# mass mixing ratio of cloud in kg/kg\n",
    "qc_fit = np.zeros((NFIT_KK,))\n",
    "# Same values, evaluation set\n",
    "nc_eval = np.zeros((NEVAL_KK,))\n",
    "qc_eval = np.zeros((NEVAL_KK,))\n",
    "\n",
    "file_name = 'kk_draws{}.nc'.format(SUFFIX)\n",
    "file_name = os.path.join(IDATA_DIR, file_name)\n",
    "if USE_CACHED_IDATA and os.path.isfile(file_name):\n",
    "    # Read data if cached.\n",
    "    with nc4.Dataset(file_name, 'r') as ncfile:\n",
    "        assert len(ncfile.dimensions['nfit']) == NFIT_KK, \\\n",
    "            \"existing data file has wrong number of fit draws\"\n",
    "        assert len(ncfile.dimensions['neval']) == NEVAL_KK, \\\n",
    "            \"existing data file has wrong number of evaluation draws\"\n",
    "        qc_fit[:] = ncfile['qc_fit'][:]\n",
    "        nc_fit[:] = ncfile['nc_fit'][:]\n",
    "        qc_eval[:] = ncfile['qc_eval'][:]\n",
    "        nc_eval[:] = ncfile['nc_eval'][:]\n",
    "else:\n",
    "    # Sample from data set.\n",
    "    num_drawn = 0\n",
    "    draws_fit = np.zeros((NFIT_KK,), dtype='i4')\n",
    "    while num_drawn < NFIT_KK:\n",
    "        i = rng.integers(data_size)\n",
    "        if draw_mask[i]:\n",
    "            draw_mask[i] = False\n",
    "            draws_fit[num_drawn] = i\n",
    "            nc_fit[num_drawn] = cliqm0s_pe[i] * rho_flattened[i] * 1.e-6\n",
    "            qc_fit[num_drawn] = cliqm3s_pe[i] * (rhow * np.pi / 6.)\n",
    "            num_drawn += 1\n",
    "    num_drawn = 0\n",
    "    draws_eval = np.zeros((NEVAL_KK,), dtype='i4')\n",
    "    while num_drawn < NEVAL_KK:\n",
    "        i = rng.integers(data_size)\n",
    "        if draw_mask[i]:\n",
    "            draw_mask[i] = False\n",
    "            draws_eval[num_drawn] = i\n",
    "            nc_eval[num_drawn] = cliqm0s_pe[i] * rho_flattened[i] * 1.e-6\n",
    "            qc_eval[num_drawn] = cliqm3s_pe[i] * (rhow * np.pi / 6.)\n",
    "            num_drawn += 1\n",
    "    # If writing cache, write out this sample.\n",
    "    if WRITE_CACHED_IDATA:\n",
    "        with nc4.Dataset(file_name, 'w', format='NETCDF4') as ncfile:\n",
    "            ncfile.createDimension('nfit', NFIT_KK)\n",
    "            ncfile.createDimension('neval', NEVAL_KK)\n",
    "            draws_fit_file = ncfile.createVariable('draws_fit', 'i4', ('nfit',))\n",
    "            qc_fit_file = ncfile.createVariable('qc_fit', 'f8', ('nfit',))\n",
    "            nc_fit_file = ncfile.createVariable('nc_fit', 'f8', ('nfit',))\n",
    "            draws_eval_file = ncfile.createVariable('draws_eval', 'i4', ('neval',))\n",
    "            qc_eval_file = ncfile.createVariable('qc_eval', 'f8', ('neval',))\n",
    "            nc_eval_file = ncfile.createVariable('nc_eval', 'f8', ('neval',))\n",
    "            draws_fit_file[:] = draws_fit\n",
    "            qc_fit_file[:] = qc_fit\n",
    "            nc_fit_file[:] = nc_fit\n",
    "            draws_eval_file[:] = draws_eval\n",
    "            qc_eval_file[:] = qc_eval\n",
    "            nc_eval_file[:] = nc_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977ee38",
   "metadata": {},
   "source": [
    "Convert sampled data to decibels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b71cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:23.414107Z",
     "start_time": "2022-01-13T20:51:23.404763Z"
    }
   },
   "outputs": [],
   "source": [
    "qc_fit_db = 10. * np.log10(qc_fit)\n",
    "nc_fit_db = 10. * np.log10(nc_fit)\n",
    "qc_eval_db = 10. * np.log10(qc_eval)\n",
    "nc_eval_db = 10. * np.log10(nc_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217ecfb",
   "metadata": {},
   "source": [
    "Values used in KK parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075dbfd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:24.609512Z",
     "start_time": "2022-01-13T20:51:24.598102Z"
    }
   },
   "outputs": [],
   "source": [
    "a_db_kk = 10.*np.log10(1350.)\n",
    "bq_kk = 2.47\n",
    "bn_kk = -1.79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4904ca5",
   "metadata": {},
   "source": [
    "Autoconversion mass rates for KK on the fit and evaluation data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f1840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:26.185461Z",
     "start_time": "2022-01-13T20:51:26.179988Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_fit_db = two_moment_power_law(a_db_kk, bq_kk, bn_kk, qc_fit_db, nc_fit_db)\n",
    "auto_eval_db = two_moment_power_law(a_db_kk, bq_kk, bn_kk, qc_eval_db, nc_eval_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375a416",
   "metadata": {},
   "source": [
    "Mass cutoff between cloud and rain is defined as `rain_auto_mass`, and is also used as the mass of all newly autoconverted rain particles. The cloud particles consumed by autoconversion have half this mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e7f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:27.099083Z",
     "start_time": "2022-01-13T20:51:27.093154Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_auto_mass = rhow * np.pi / 6. * (CLOUD_RAIN_CUTOFF)**3.\n",
    "rain_auto_mass_db = 10. * np.log10(rain_auto_mass)\n",
    "cloud_auto_mass = 0.5 * rain_auto_mass\n",
    "cloud_auto_mass_db = 10. * np.log10(cloud_auto_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd1978",
   "metadata": {},
   "source": [
    "Number rates associated with the KK mass rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176864f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:28.104583Z",
     "start_time": "2022-01-13T20:51:28.099509Z"
    }
   },
   "outputs": [],
   "source": [
    "nc_auto_fit_db = auto_fit_db - cloud_auto_mass_db\n",
    "nr_auto_fit_db = auto_fit_db - rain_auto_mass_db\n",
    "nc_auto_eval_db = auto_eval_db - cloud_auto_mass_db\n",
    "nr_auto_eval_db = auto_eval_db - rain_auto_mass_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9f4d3",
   "metadata": {},
   "source": [
    "## Uncorrelated errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42586ed",
   "metadata": {},
   "source": [
    "List of parameter names, for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd454ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:30.565527Z",
     "start_time": "2022-01-13T20:51:30.561055Z"
    }
   },
   "outputs": [],
   "source": [
    "uncorr_parameters = ['a_db', 'bq', 'bn', 'mean_mc_db', 'mean_mr_db', 'sigma_q', 'sigma_nc', 'sigma_nr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06121a38",
   "metadata": {},
   "source": [
    "Add error term to data; $\\sigma=1\\text{db}$ for each observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb4885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:32.291174Z",
     "start_time": "2022-01-13T20:51:32.254236Z"
    }
   },
   "outputs": [],
   "source": [
    "rate_q_obs = np.zeros((NFIT_KK,))\n",
    "rate_nc_obs = np.zeros((NFIT_KK,))\n",
    "rate_nr_obs = np.zeros((NFIT_KK,))\n",
    "rate_q_obs_eval = np.zeros((NEVAL_KK,))\n",
    "rate_nc_obs_eval = np.zeros((NEVAL_KK,))\n",
    "rate_nr_obs_eval = np.zeros((NEVAL_KK,))\n",
    "\n",
    "file_name = 'kk_uncorr_obs{}.nc'.format(SUFFIX)\n",
    "file_name = os.path.join(IDATA_DIR, file_name)\n",
    "if USE_CACHED_IDATA and os.path.isfile(file_name):\n",
    "    # Read data if cached.\n",
    "    with nc4.Dataset(file_name, 'r') as ncfile:\n",
    "        assert len(ncfile.dimensions['nfit']) == NFIT_KK, \\\n",
    "            \"existing data file has wrong number of fit draws\"\n",
    "        assert len(ncfile.dimensions['neval']) == NEVAL_KK, \\\n",
    "            \"existing data file has wrong number of evaluation draws\"\n",
    "        rate_q_obs[:] = ncfile['rate_q_fit'][:]\n",
    "        rate_nc_obs[:] = ncfile['rate_nc_fit'][:]\n",
    "        rate_nr_obs[:] = ncfile['rate_nr_fit'][:]\n",
    "        rate_q_obs_eval[:] = ncfile['rate_q_eval'][:]\n",
    "        rate_nc_obs_eval[:] = ncfile['rate_nc_eval'][:]\n",
    "        rate_nr_obs_eval[:] = ncfile['rate_nr_eval'][:]\n",
    "else:\n",
    "    # Produce random error and add it to autoconversion rates.\n",
    "    y = pm.Normal.dist(mu=0., tau=1.)\n",
    "    y_obs = y.random(size=3*NFIT_KK)\n",
    "    rate_q_obs = auto_fit_db + y_obs[0:NFIT_KK]\n",
    "    rate_nc_obs = nc_auto_fit_db + y_obs[NFIT_KK:2*NFIT_KK]\n",
    "    rate_nr_obs = nr_auto_fit_db + y_obs[2*NFIT_KK:3*NFIT_KK]\n",
    "    y_obs_eval = y.random(size=3*NEVAL_KK)\n",
    "    rate_q_obs_eval = auto_eval_db + y_obs[0:NEVAL_KK]\n",
    "    rate_nc_obs_eval = nc_auto_eval_db + y_obs[NEVAL_KK:2*NEVAL_KK]\n",
    "    rate_nr_obs_eval = nr_auto_eval_db + y_obs[2*NEVAL_KK:3*NEVAL_KK]\n",
    "    # If writing cache, write out this sample.\n",
    "    if WRITE_CACHED_IDATA:\n",
    "        with nc4.Dataset(file_name, 'w', format='NETCDF4') as ncfile:\n",
    "            ncfile.createDimension('nfit', NFIT_KK)\n",
    "            ncfile.createDimension('neval', NEVAL_KK)\n",
    "            rate_q_fit_file = ncfile.createVariable('rate_q_fit', 'f8', ('nfit',))\n",
    "            rate_nc_fit_file = ncfile.createVariable('rate_nc_fit', 'f8', ('nfit',))\n",
    "            rate_nr_fit_file = ncfile.createVariable('rate_nr_fit', 'f8', ('nfit',))\n",
    "            rate_q_eval_file = ncfile.createVariable('rate_q_eval', 'f8', ('neval',))\n",
    "            rate_nc_eval_file = ncfile.createVariable('rate_nc_eval', 'f8', ('neval',))\n",
    "            rate_nr_eval_file = ncfile.createVariable('rate_nr_eval', 'f8', ('neval',))\n",
    "            rate_q_fit_file[:] = rate_q_obs\n",
    "            rate_nc_fit_file[:] = rate_nc_obs\n",
    "            rate_nr_fit_file[:] = rate_nr_obs\n",
    "            rate_q_eval_file[:] = rate_q_obs_eval\n",
    "            rate_nc_eval_file[:] = rate_nc_obs_eval\n",
    "            rate_nr_eval_file[:] = rate_nr_obs_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a6ff8",
   "metadata": {},
   "source": [
    "Find minimum value of observations that will be used in decibels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee756ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:33.329517Z",
     "start_time": "2022-01-13T20:51:33.324520Z"
    }
   },
   "outputs": [],
   "source": [
    "min_q_auto_uncorr_db = rate_q_obs.max() + min_obs_fac_db\n",
    "min_nc_auto_uncorr_db = rate_nc_obs.max() + min_obs_fac_db\n",
    "min_nr_auto_uncorr_db = rate_nr_obs.max() + min_obs_fac_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33095be",
   "metadata": {},
   "source": [
    "Limited values of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dab8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:33.951475Z",
     "start_time": "2022-01-13T20:51:33.941224Z"
    }
   },
   "outputs": [],
   "source": [
    "rate_q_obslim_uncorr = np.maximum(rate_q_obs, min_q_auto_uncorr_db)\n",
    "rate_nc_obslim_uncorr = np.maximum(rate_nc_obs, min_nc_auto_uncorr_db)\n",
    "rate_nr_obslim_uncorr = np.maximum(rate_nr_obs, min_nr_auto_uncorr_db)\n",
    "obs_data_uncorr = np.zeros((NFIT_KK, 3))\n",
    "obs_data_uncorr[:,0] = rate_q_obslim_uncorr\n",
    "obs_data_uncorr[:,1] = rate_nc_obslim_uncorr\n",
    "obs_data_uncorr[:,2] = rate_nr_obslim_uncorr\n",
    "obs_data_eval_uncorr = np.zeros((NEVAL_KK, 3))\n",
    "obs_data_eval_uncorr[:,0] = np.maximum(rate_q_obs_eval, min_q_auto_uncorr_db)\n",
    "obs_data_eval_uncorr[:,1] = np.maximum(rate_nc_obs_eval, min_nc_auto_uncorr_db)\n",
    "obs_data_eval_uncorr[:,2] = np.maximum(rate_nr_obs_eval, min_nr_auto_uncorr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf34320",
   "metadata": {},
   "source": [
    "Dictionary of values needed by physical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1fa60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:34.323768Z",
     "start_time": "2022-01-13T20:51:34.319179Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_kwargs_uncorr = {\n",
    "    'qc_db': qc_fit_db,\n",
    "    'nc_db': nc_fit_db,\n",
    "    'min_q_auto_db': min_q_auto_uncorr_db,\n",
    "    'min_nc_auto_db': min_nc_auto_uncorr_db,\n",
    "    'min_nr_auto_db': min_nr_auto_uncorr_db,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa1bd3",
   "metadata": {},
   "source": [
    "Define variable names to use for names of error parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f47c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:51:35.807698Z",
     "start_time": "2022-01-13T20:51:35.803157Z"
    }
   },
   "outputs": [],
   "source": [
    "var_names = ['q', 'nc', 'nr']\n",
    "error_kwargs_uncorr = {\n",
    "    'var_names': var_names,\n",
    "}\n",
    "post_kwargs_uncorr = {\n",
    "    'var_names': var_names,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161d9e5",
   "metadata": {},
   "source": [
    "### With explicit sigma parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b65bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:53:55.329301Z",
     "start_time": "2022-01-13T20:51:37.618677Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_uncorr = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_multiple,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        file_prefix='kk_idata_uncorr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ec904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:53:55.764028Z",
     "start_time": "2022-01-13T20:53:55.331585Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7101f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:53:58.932176Z",
     "start_time": "2022-01-13T20:53:55.765513Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a3fb64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:05.971945Z",
     "start_time": "2022-01-13T15:18:05.924403Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts_uncorr = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        file_prefix='kk_idata_nuts_uncorr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594dd2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:06.479012Z",
     "start_time": "2022-01-13T15:18:05.973009Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253807c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:10.450170Z",
     "start_time": "2022-01-13T15:18:06.480411Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c395a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:15.387684Z",
     "start_time": "2022-01-13T15:18:10.451672Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(idata_nuts_uncorr, uncorr_parameters, divergences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1274e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:21.339287Z",
     "start_time": "2022-01-13T15:18:15.389253Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(idata_nuts_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997f630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:21.392166Z",
     "start_time": "2022-01-13T15:18:21.341036Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_uncorr = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        file_prefix='kk_idata_nuts95_uncorr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39ff62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:21.833407Z",
     "start_time": "2022-01-13T15:18:21.393298Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82145ad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:18:25.773263Z",
     "start_time": "2022-01-13T15:18:21.834806Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_uncorr, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a930f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:17.360078Z",
     "start_time": "2022-01-13T15:18:25.774806Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_kk(idata_nuts95_uncorr, obs_data_eval_uncorr, qc_eval_db, nc_eval_db,\n",
    "                               min_q_auto_uncorr_db, min_nc_auto_uncorr_db, min_nr_auto_uncorr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6182bb",
   "metadata": {},
   "source": [
    "### With conjugate prior method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a95147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:56:17.679624Z",
     "start_time": "2022-01-13T20:53:58.934485Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_uncorr_conjp = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_conjp_multiple,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        post_mcmc_sample=add_sigma_samples_multiple,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        post_kwargs=post_kwargs_uncorr,\n",
    "        file_prefix='kk_idata_uncorr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22265947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:56:18.226847Z",
     "start_time": "2022-01-13T20:56:17.681314Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed0afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:56:28.722571Z",
     "start_time": "2022-01-13T20:56:24.278184Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14995f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:21.580821Z",
     "start_time": "2022-01-13T15:20:21.544019Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts_uncorr_conjp = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_conjp_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_sigma_samples_multiple,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        post_kwargs=post_kwargs_uncorr,\n",
    "        file_prefix='kk_idata_nuts_uncorr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27a890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:22.039660Z",
     "start_time": "2022-01-13T15:20:21.582048Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37008261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:26.099246Z",
     "start_time": "2022-01-13T15:20:22.040865Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f897e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:31.652962Z",
     "start_time": "2022-01-13T15:20:26.100779Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(idata_nuts_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7feb79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:31.691233Z",
     "start_time": "2022-01-13T15:20:31.654479Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_uncorr_conjp = run_mcmc(\n",
    "        obs=obs_data_uncorr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_uncorrelated_error_conjp_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_sigma_samples_multiple,\n",
    "        physical_kwargs=physical_kwargs_uncorr,\n",
    "        error_kwargs=error_kwargs_uncorr,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        post_kwargs=post_kwargs_uncorr,\n",
    "        file_prefix='kk_idata_nuts95_uncorr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd8376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:32.116842Z",
     "start_time": "2022-01-13T15:20:31.692683Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5b4a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:20:36.303457Z",
     "start_time": "2022-01-13T15:20:32.118220Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_uncorr_conjp, uncorr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf2f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:22:28.430260Z",
     "start_time": "2022-01-13T15:20:36.304944Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_kk(idata_nuts95_uncorr_conjp, obs_data_eval_uncorr, qc_eval_db, nc_eval_db,\n",
    "                               min_q_auto_uncorr_db, min_nc_auto_uncorr_db, min_nr_auto_uncorr_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0e42f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.190134Z",
     "start_time": "2022-01-13T15:22:28.432076Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_conjp_kk(idata_nuts95_uncorr_conjp, NFIT_KK, obs_data_eval_uncorr,\n",
    "                                     qc_eval_db, nc_eval_db,\n",
    "                                     min_q_auto_uncorr_db, min_nc_auto_uncorr_db, min_nr_auto_uncorr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01f708",
   "metadata": {},
   "source": [
    "## Correlated errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c4ce5",
   "metadata": {},
   "source": [
    "List of parameter names, for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68493541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.199840Z",
     "start_time": "2022-01-13T15:24:20.197100Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_parameters = ['a_db', 'bq', 'bn', 'mean_mc_db', 'mean_mr_db', 'omega_chol_elems']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c1a3d",
   "metadata": {},
   "source": [
    "With correlated errors it becomes more difficult to find the high-probability region of the parameter space, especially with the conjugate prior method. Therefore we also run cases that start much closer to this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbe083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.215985Z",
     "start_time": "2022-01-13T15:24:20.200994Z"
    }
   },
   "outputs": [],
   "source": [
    "close_testvals = [a_db_kk, bq_kk, bn_kk, cloud_auto_mass_db, rain_auto_mass_db]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a236",
   "metadata": {},
   "source": [
    "Construction of precision matrix. Roughly speaking, this matrix represents a case where the most uncertainty is in the overall level of autoconversion along lines of constant particle size, followed by uncertainty in the mean mass of autoconverted particles, with the least uncertainty in the ratio between the mean mass of autoconverted cloud particles and the mean mass of rain produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4d47d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.224387Z",
     "start_time": "2022-01-13T15:24:20.217373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start with this orthonormal matrix giving the directions of major/mean/minor axes.\n",
    "u = np.array([\n",
    "    [1./np.sqrt(3.),  2./np.sqrt(6.),              0.],\n",
    "    [1./np.sqrt(3.), -1./np.sqrt(6.),  1./np.sqrt(2.)],\n",
    "    [1./np.sqrt(3.), -1./np.sqrt(6.), -1./np.sqrt(2.)],\n",
    "])\n",
    "# First eigenvalue of covariance matrix is (2 db)^2, second is (1 db)^2, third is (0.5 db)^2.\n",
    "lam = np.diag(np.array([1. / (2.**2), 1. / (1.**2), 1. / (0.5**2)]))\n",
    "omega = np.matmul(u, np.matmul(lam, u.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54eedf",
   "metadata": {},
   "source": [
    "Print precision matrix and its lower triangular Cholesky factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40c3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.236561Z",
     "start_time": "2022-01-13T15:24:20.225631Z"
    }
   },
   "outputs": [],
   "source": [
    "print(omega)\n",
    "print(la.cholesky(omega, lower=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ed7b8",
   "metadata": {},
   "source": [
    "Add error term to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b843e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.253354Z",
     "start_time": "2022-01-13T15:24:20.237944Z"
    }
   },
   "outputs": [],
   "source": [
    "rate_q_obs_corr = np.zeros((NFIT_KK,))\n",
    "rate_nc_obs_corr = np.zeros((NFIT_KK,))\n",
    "rate_nr_obs_corr = np.zeros((NFIT_KK,))\n",
    "rate_q_obs_eval_corr = np.zeros((NEVAL_KK,))\n",
    "rate_nc_obs_eval_corr = np.zeros((NEVAL_KK,))\n",
    "rate_nr_obs_eval_corr = np.zeros((NEVAL_KK,))\n",
    "\n",
    "file_name = 'kk_corr_obs{}.nc'.format(SUFFIX)\n",
    "file_name = os.path.join(IDATA_DIR, file_name)\n",
    "if USE_CACHED_IDATA and os.path.isfile(file_name):\n",
    "    # Read data if cached.\n",
    "    with nc4.Dataset(file_name, 'r') as ncfile:\n",
    "        assert len(ncfile.dimensions['nfit']) == NFIT_KK, \\\n",
    "            \"existing data file has wrong number of fit draws\"\n",
    "        assert len(ncfile.dimensions['neval']) == NEVAL_KK, \\\n",
    "            \"existing data file has wrong number of evaluation draws\"\n",
    "        rate_q_obs_corr[:] = ncfile['rate_q_fit'][:]\n",
    "        rate_nc_obs_corr[:] = ncfile['rate_nc_fit'][:]\n",
    "        rate_nr_obs_corr[:] = ncfile['rate_nr_fit'][:]\n",
    "        rate_q_obs_eval_corr[:] = ncfile['rate_q_eval'][:]\n",
    "        rate_nc_obs_eval_corr[:] = ncfile['rate_nc_eval'][:]\n",
    "        rate_nr_obs_eval_corr[:] = ncfile['rate_nr_eval'][:]\n",
    "        # For diagnostic in next cell.\n",
    "        y_obs = np.zeros((3, NFIT_KK))\n",
    "        y_obs[0,:] = rate_q_obs_corr - auto_fit_db\n",
    "        y_obs[1,:] = rate_nc_obs_corr - nc_auto_fit_db\n",
    "        y_obs[2,:] = rate_nr_obs_corr - nr_auto_fit_db\n",
    "else:\n",
    "    y = pm.MvNormal.dist(mu=np.array([0., 0., 0.]), tau=omega, shape=(3,))\n",
    "    y_obs = y.random(size=NFIT_KK).T\n",
    "    rate_q_obs_corr = auto_fit_db + y_obs[0,:]\n",
    "    rate_nc_obs_corr = nc_auto_fit_db + y_obs[1,:]\n",
    "    rate_nr_obs_corr = nr_auto_fit_db + y_obs[2,:]\n",
    "    y_obs_eval = y.random(size=NEVAL_KK).T\n",
    "    rate_q_obs_eval_corr = auto_eval_db + y_obs_eval[0,:]\n",
    "    rate_nc_obs_eval_corr = nc_auto_eval_db + y_obs_eval[1,:]\n",
    "    rate_nr_obs_eval_corr = nr_auto_eval_db + y_obs_eval[2,:]\n",
    "    # If writing cache, write out this sample.\n",
    "    if WRITE_CACHED_IDATA:\n",
    "        with nc4.Dataset(file_name, 'w', format='NETCDF4') as ncfile:\n",
    "            ncfile.createDimension('nfit', NFIT_KK)\n",
    "            ncfile.createDimension('neval', NEVAL_KK)\n",
    "            rate_q_fit_file = ncfile.createVariable('rate_q_fit', 'f8', ('nfit',))\n",
    "            rate_nc_fit_file = ncfile.createVariable('rate_nc_fit', 'f8', ('nfit',))\n",
    "            rate_nr_fit_file = ncfile.createVariable('rate_nr_fit', 'f8', ('nfit',))\n",
    "            rate_q_eval_file = ncfile.createVariable('rate_q_eval', 'f8', ('neval',))\n",
    "            rate_nc_eval_file = ncfile.createVariable('rate_nc_eval', 'f8', ('neval',))\n",
    "            rate_nr_eval_file = ncfile.createVariable('rate_nr_eval', 'f8', ('neval',))\n",
    "            rate_q_fit_file[:] = rate_q_obs_corr\n",
    "            rate_nc_fit_file[:] = rate_nc_obs_corr\n",
    "            rate_nr_fit_file[:] = rate_nr_obs_corr\n",
    "            rate_q_eval_file[:] = rate_q_obs_eval_corr\n",
    "            rate_nc_eval_file[:] = rate_nc_obs_eval_corr\n",
    "            rate_nr_eval_file[:] = rate_nr_obs_eval_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efbbb0",
   "metadata": {},
   "source": [
    "Inverse of covariance of the error term should approximately equal the precision matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de5ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.260725Z",
     "start_time": "2022-01-13T15:24:20.254834Z"
    }
   },
   "outputs": [],
   "source": [
    "print(la.inv(np.cov(y_obs)))\n",
    "print(la.cholesky(la.inv(np.cov(y_obs)), lower=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118c0aa",
   "metadata": {},
   "source": [
    "Limit observed values and put all variables in a single array for later convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb46ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.267461Z",
     "start_time": "2022-01-13T15:24:20.262016Z"
    }
   },
   "outputs": [],
   "source": [
    "min_q_auto_corr_db = rate_q_obs_corr.max() + min_obs_fac_db\n",
    "min_nc_auto_corr_db = rate_nc_obs_corr.max() + min_obs_fac_db\n",
    "min_nr_auto_corr_db = rate_nr_obs_corr.max() + min_obs_fac_db\n",
    "rate_q_obslim_corr = np.maximum(rate_q_obs_corr, min_q_auto_corr_db)\n",
    "rate_nc_obslim_corr = np.maximum(rate_nc_obs_corr, min_nc_auto_corr_db)\n",
    "rate_nr_obslim_corr = np.maximum(rate_nr_obs_corr, min_nr_auto_corr_db)\n",
    "obs_data_corr = np.zeros((NFIT_KK, 3))\n",
    "obs_data_corr[:,0] = rate_q_obslim_corr\n",
    "obs_data_corr[:,1] = rate_nc_obslim_corr\n",
    "obs_data_corr[:,2] = rate_nr_obslim_corr\n",
    "obs_data_eval_corr = np.zeros((NEVAL_KK, 3))\n",
    "obs_data_eval_corr[:,0] = np.maximum(rate_q_obs_eval_corr, min_q_auto_corr_db)\n",
    "obs_data_eval_corr[:,1] = np.maximum(rate_nc_obs_eval_corr, min_nc_auto_corr_db)\n",
    "obs_data_eval_corr[:,2] = np.maximum(rate_nr_obs_eval_corr, min_nr_auto_corr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6451fc5",
   "metadata": {},
   "source": [
    "Look at inverse covariance of error in the limited data. The limiter changes this estimate of the precision matrix more than the limited observation sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c4c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.279384Z",
     "start_time": "2022-01-13T15:24:20.268931Z"
    }
   },
   "outputs": [],
   "source": [
    "model_data = np.zeros((NFIT_KK, 3))\n",
    "model_data[:,0] = auto_fit_db\n",
    "model_data[:,1] = nc_auto_fit_db\n",
    "model_data[:,2] = nr_auto_fit_db\n",
    "cov = np.cov((obs_data_corr-model_data).T)\n",
    "inv = la.inv(cov)\n",
    "print(inv)\n",
    "chol = la.cholesky(inv, lower=True)\n",
    "print(chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b7701",
   "metadata": {},
   "source": [
    "Save the cholesky decomposition of this matrix for use as a \"close\" starting point to the high-probability region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c20ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.284602Z",
     "start_time": "2022-01-13T15:24:20.280860Z"
    }
   },
   "outputs": [],
   "source": [
    "cholesky_estimate = lower_tri_to_elements(chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f29a4b",
   "metadata": {},
   "source": [
    "Dictionaries of values needed by physical model. To start MCMC close to the high-probability region, we need to pass `testvals=close_testvals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70f9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.292478Z",
     "start_time": "2022-01-13T15:24:20.285868Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_kwargs_corr_distant = {\n",
    "    'qc_db': qc_fit_db,\n",
    "    'nc_db': nc_fit_db,\n",
    "    'min_q_auto_db': min_q_auto_corr_db,\n",
    "    'min_nc_auto_db': min_nc_auto_corr_db,\n",
    "    'min_nr_auto_db': min_nr_auto_corr_db,\n",
    "}\n",
    "physical_kwargs_corr_close = physical_kwargs_corr_distant.copy()\n",
    "physical_kwargs_corr_close['testvals'] = close_testvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad404004",
   "metadata": {},
   "source": [
    "### With explicit precision matrix entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9582d66",
   "metadata": {},
   "source": [
    "Dictionaries of values needed by error model. To start MCMC close to the high-probability region, we need to pass `chol_testvals=cholesky_estimate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45daa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.300501Z",
     "start_time": "2022-01-13T15:24:20.293750Z"
    }
   },
   "outputs": [],
   "source": [
    "error_kwargs_corr_distant = {\n",
    "    'name': 'rates',\n",
    "    'omega_name': 'omega',\n",
    "    'omega_chol_name': 'omega_chol_elems'\n",
    "}\n",
    "error_kwargs_corr_close = error_kwargs_corr_distant.copy()\n",
    "error_kwargs_corr_close['chol_testvals'] = cholesky_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d7bf7",
   "metadata": {},
   "source": [
    "#### Distant starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45aace7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:20.345883Z",
     "start_time": "2022-01-13T15:24:20.301893Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_corr = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        physical_kwargs=physical_kwargs_corr_distant,\n",
    "        error_kwargs=error_kwargs_corr_distant,\n",
    "        file_prefix='kk_idata_corr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40906b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:21.258464Z",
     "start_time": "2022-01-13T15:24:20.347321Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_corr, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe2c97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:25.957514Z",
     "start_time": "2022-01-13T15:24:21.260366Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd318b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:26.008617Z",
     "start_time": "2022-01-13T15:24:25.959105Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_corr = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_corr_distant,\n",
    "        error_kwargs=error_kwargs_corr_distant,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        file_prefix='kk_idata_nuts95_corr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349d5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:26.862477Z",
     "start_time": "2022-01-13T15:24:26.010151Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_corr, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3e6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:32.308051Z",
     "start_time": "2022-01-13T15:24:26.863954Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_corr, corr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bc320",
   "metadata": {},
   "source": [
    "#### Close starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500d956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:32.349299Z",
     "start_time": "2022-01-13T15:24:32.309638Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_corr_close = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        physical_kwargs=physical_kwargs_corr_close,\n",
    "        error_kwargs=error_kwargs_corr_close,\n",
    "        file_prefix='kk_idata_corr_close',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354024fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:33.178229Z",
     "start_time": "2022-01-13T15:24:32.350794Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_corr_close, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066fa50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:37.817114Z",
     "start_time": "2022-01-13T15:24:33.179641Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr_close, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4433cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:37.865893Z",
     "start_time": "2022-01-13T15:24:37.818611Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_corr_close = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_corr_close,\n",
    "        error_kwargs=error_kwargs_corr_close,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        file_prefix='kk_idata_nuts95_corr_close',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfc63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:38.701843Z",
     "start_time": "2022-01-13T15:24:37.867367Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_corr_close, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe30aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:44.091495Z",
     "start_time": "2022-01-13T15:24:38.703494Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_corr_close, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b5586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:24:53.412188Z",
     "start_time": "2022-01-13T15:24:44.093145Z"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_pair(idata_nuts95_corr_close,\n",
    "             var_names=corr_parameters,\n",
    "             kind=['kde'], marginals=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9187b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:24.081684Z",
     "start_time": "2022-01-13T15:24:53.413766Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_kk(idata_nuts95_corr_close, obs_data_eval_corr, qc_eval_db, nc_eval_db,\n",
    "                             min_q_auto_corr_db, min_nc_auto_corr_db, min_nr_auto_corr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c6fb7",
   "metadata": {},
   "source": [
    "### With conjugate prior method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db291357",
   "metadata": {},
   "source": [
    "Dictionary of values needed by error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d90891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:24.086265Z",
     "start_time": "2022-01-13T15:26:24.083351Z"
    }
   },
   "outputs": [],
   "source": [
    "error_kwargs_corr_conjp = {\n",
    "    'output_name': 'log_like',\n",
    "    'sum_sq_err_name': 'sum_sq_err',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15cc73",
   "metadata": {},
   "source": [
    "Dictionary of values needed by post-MCMC sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4430ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:24.100435Z",
     "start_time": "2022-01-13T15:26:24.087615Z"
    }
   },
   "outputs": [],
   "source": [
    "post_kwargs_corr = {\n",
    "    'sum_sq_err_name': 'sum_sq_err',\n",
    "    'omega_name': 'omega',\n",
    "    'omega_chol_name': 'omega_chol_elems',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d318f7",
   "metadata": {},
   "source": [
    "#### Distant starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66e4d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:24.137556Z",
     "start_time": "2022-01-13T15:26:24.101743Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_corr_conjp = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_corr_distant,\n",
    "        error_kwargs=error_kwargs_corr_conjp,\n",
    "        post_kwargs=post_kwargs_corr,\n",
    "        file_prefix='kk_idata_corr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d306d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:26.361386Z",
     "start_time": "2022-01-13T15:26:24.138728Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_corr_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc9887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:31.205958Z",
     "start_time": "2022-01-13T15:26:26.363057Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0060de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:36.491607Z",
     "start_time": "2022-01-13T15:26:31.207477Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr_conjp, corr_parameters, kind='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe6c80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:36.529813Z",
     "start_time": "2022-01-13T15:26:36.493225Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_corr_conjp = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_corr_distant,\n",
    "        error_kwargs=error_kwargs_corr_conjp,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        post_kwargs=post_kwargs_corr,\n",
    "        file_prefix='kk_idata_nuts95_corr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fedcb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:37.796978Z",
     "start_time": "2022-01-13T15:26:36.531061Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_corr_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23378ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:42.864350Z",
     "start_time": "2022-01-13T15:26:37.799474Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_corr_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9368b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:51.946906Z",
     "start_time": "2022-01-13T15:26:42.865660Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(idata_nuts95_corr_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4defabc4",
   "metadata": {},
   "source": [
    "#### Close starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497d41e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:51.979586Z",
     "start_time": "2022-01-13T15:26:51.948550Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_corr_close_conjp = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_corr_close,\n",
    "        error_kwargs=error_kwargs_corr_conjp,\n",
    "        post_kwargs=post_kwargs_corr,\n",
    "        file_prefix='kk_idata_corr_close_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a344554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:53.642349Z",
     "start_time": "2022-01-13T15:26:51.981002Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_corr_close_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d3eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:26:58.845888Z",
     "start_time": "2022-01-13T15:26:53.643848Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr_close_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7559a90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:27:05.764516Z",
     "start_time": "2022-01-13T15:26:58.847683Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_corr_close_conjp, corr_parameters, kind='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38084c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:27:05.806500Z",
     "start_time": "2022-01-13T15:27:05.766291Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    idata_nuts95_corr_close_conjp = run_mcmc(\n",
    "        obs=obs_data_corr,\n",
    "        physical_model=define_physical_model_kk,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_corr_close,\n",
    "        error_kwargs=error_kwargs_corr_conjp,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        post_kwargs=post_kwargs_corr,\n",
    "        file_prefix='kk_idata_nuts95_corr_close_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f29db1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:27:07.064252Z",
     "start_time": "2022-01-13T15:27:05.807888Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(idata_nuts95_corr_close_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63c15e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:27:12.454090Z",
     "start_time": "2022-01-13T15:27:07.065650Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(idata_nuts95_corr_close_conjp, corr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca789ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:28:45.221047Z",
     "start_time": "2022-01-13T15:27:12.455650Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_kk(idata_nuts95_corr_close_conjp, obs_data_eval_corr, qc_eval_db, nc_eval_db,\n",
    "                             min_q_auto_corr_db, min_nc_auto_corr_db, min_nr_auto_corr_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be513174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T15:30:18.694199Z",
     "start_time": "2022-01-13T15:28:45.222822Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_conjp_kk(idata_nuts95_corr_close_conjp, NEVAL_KK, obs_data_eval_corr,\n",
    "                                   qc_eval_db, nc_eval_db,\n",
    "                                   min_q_auto_corr_db, min_nc_auto_corr_db, min_nr_auto_corr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f293cc6",
   "metadata": {},
   "source": [
    "# Bin Model Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98363c",
   "metadata": {},
   "source": [
    "## User settings and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec8073",
   "metadata": {},
   "source": [
    "Number of points for MCMC integration and evaluation of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389bb25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:27.055406Z",
     "start_time": "2022-01-13T20:59:27.050407Z"
    }
   },
   "outputs": [],
   "source": [
    "NFIT_BIN = 10000\n",
    "NEVAL_BIN = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da4db6",
   "metadata": {},
   "source": [
    "Random seed for drawing from input dataset changed, to ensure we draw different points from the KK example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c99b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:27.309966Z",
     "start_time": "2022-01-13T20:59:27.305703Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED_BIN = 87630560"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1eabf3",
   "metadata": {},
   "source": [
    "Location and width of priors for physical model parameters. These values are taken from a more extensive study of the BOSS microphysics framework. Note that based on theoretical considerations, $b_{n,rd} \\in [0,2]$, since otherwise the autoconversion rate would go to infinity as either cloud amount goes to zero (if $b_{n,rd} > 2$) or rain amount goes to zero (if $b_{n,rd} < 0$). In the code $b_{n,rd}$ is labelled `brdr0`, so instead of a Gaussian prior for this variable, we use a uniform prior on $[0, 2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa01bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:01:15.506555Z",
     "start_time": "2022-01-13T22:01:15.497550Z"
    }
   },
   "outputs": [],
   "source": [
    "BIN_MU_A_DB = 1450.\n",
    "BIN_SIGMA_A_DB = 100.\n",
    "BIN_MU_B = 13.2\n",
    "BIN_SIGMA_B = 2.\n",
    "BIN_MU_ARD_DB = -211.\n",
    "BIN_SIGMA_ARD_DB = 100.\n",
    "BIN_MU_BRDC = 1.45\n",
    "BIN_SIGMA_BRDC = 2.\n",
    "BIN_MU_BRDR3 = -1.50\n",
    "BIN_SIGMA_BRDR3 = 2.\n",
    "BIN_TESTVAL_BRDR0 = 0.77\n",
    "BIN_MU_MEAN_MC_DB = -126.\n",
    "BIN_SIGMA_MEAN_MC_DB = 30.\n",
    "BIN_MU_MEAN_MR_DB = -123.\n",
    "BIN_SIGMA_MEAN_MR_DB = 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8267df",
   "metadata": {},
   "source": [
    "## Physical model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc099c",
   "metadata": {},
   "source": [
    "Define 2-term power law model for autoconversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686dd93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:27.851610Z",
     "start_time": "2022-01-13T20:59:27.841331Z"
    }
   },
   "outputs": [],
   "source": [
    "def rain_dependent_auto_power_law(a_db, b, ard_db, brdc, brdr3, brdr0,\n",
    "                                  cm0_db, cm3_db, rm0_db, rm3_db,\n",
    "                                  rain_mask, disable_theano=False):\n",
    "    \"\"\"Calculate autoconversion rate in decibels from model parameters and two moments of cloud and rain.\n",
    "\n",
    "    Arguments:\n",
    "    a_db - Rain-independent power law coefficient in decibels\n",
    "    b - Rain-independent power law exponent\n",
    "    ard_db - Rain-dependent power law coefficient in decibels\n",
    "    brdc, brdr3, brdr0 - Rain-dependent power law exponents\n",
    "    cm0_db, cm3_db - Cloud moments (#/kg and m^3/kg) in decibels\n",
    "    rm0_db, rm3_db - Rain moments (#/kg and m^3/kg) in decibels\n",
    "    rain_mask - Mask for locations where rain-dependent term is evaluated (i.e. rain is present).\n",
    "    disable_theano (optional) - Whether to work with floats directly rather than Theano variables.\n",
    "                                Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    Theano variable for autoconversion mass rate (kg/kg/s) in decibels. If disable_theano is True,\n",
    "    returned value is a float or ndarray.\n",
    "    \"\"\"\n",
    "    if disable_theano:\n",
    "        log10 = np.log10\n",
    "        where = np.where\n",
    "    else:\n",
    "        log10 = tt.log10\n",
    "        where = tt.where\n",
    "    first_term = a_db + b * cm3_db + (2. - b) * cm0_db\n",
    "    second_term = ard_db + brdc * cm3_db + (2. - brdc - brdr0) * cm0_db + \\\n",
    "                  brdr3 * rm3_db + (brdr0 - brdr3) * rm0_db\n",
    "    # This is equivalent to converting both terms from decibels to natural units, adding, and\n",
    "    # converting back to decibels. We do it this way because it halves the number of `pow` calls.\n",
    "    return first_term + where(rain_mask, 10.*log10(1. + 10.**((second_term - first_term)/10.)), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ed376",
   "metadata": {},
   "source": [
    "Set priors for physical model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69136d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:28.133850Z",
     "start_time": "2022-01-13T20:59:28.121079Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_priors_bin(testvals=None):\n",
    "    \"\"\"Define priors for a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, and mean_mr_db.\n",
    "\n",
    "    Must be called in from a context with an active PyMC3 model.\n",
    "    Arguments:\n",
    "    testvals (optional) - Used to define the integration starting points for MCMC.\n",
    "                          If not provided, the prior means will be used for these values.\n",
    "                          If provided, 'testvals' must contain values for all five variables.\n",
    "\n",
    "    Returns:\n",
    "    (a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db)\n",
    "    \"\"\"\n",
    "    if testvals is None:\n",
    "        testvals = [BIN_MU_A_DB, BIN_MU_B, BIN_MU_ARD_DB, BIN_MU_BRDC,\n",
    "                    BIN_MU_BRDR3, BIN_TESTVAL_BRDR0, BIN_MU_MEAN_MC_DB, BIN_MU_MEAN_MR_DB]\n",
    "    a_db = pm.Normal('a_db', mu=BIN_MU_A_DB, sigma=BIN_SIGMA_A_DB, testval=testvals[0])\n",
    "    b = pm.Normal('b', mu=BIN_MU_B, sigma=BIN_SIGMA_B, testval=testvals[1])\n",
    "    ard_db = pm.Normal('ard_db', mu=BIN_MU_ARD_DB, sigma=BIN_SIGMA_ARD_DB, testval=testvals[2])\n",
    "    brdc = pm.Normal('brdc', mu=BIN_MU_BRDC, sigma=BIN_SIGMA_BRDC, testval=testvals[3])\n",
    "    brdr3 = pm.Normal('brdr3', mu=BIN_MU_BRDR3, sigma=BIN_SIGMA_BRDR3, testval=testvals[4])\n",
    "    brdr0 = pm.Uniform('brdr0', lower=0., upper=2., testval=testvals[5])\n",
    "    mean_mc_db = pm.Normal('mean_mc_db', mu=BIN_MU_MEAN_MC_DB, sigma=BIN_SIGMA_MEAN_MC_DB,\n",
    "                           testval=testvals[6])\n",
    "    mean_mr_db = pm.Normal('mean_mr_db', mu=BIN_MU_MEAN_MR_DB, sigma=BIN_SIGMA_MEAN_MR_DB,\n",
    "                           testval=testvals[7])\n",
    "    return (a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e3f6a",
   "metadata": {},
   "source": [
    "Evaluate physical model given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a889b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:29.169494Z",
     "start_time": "2022-01-13T20:59:29.156517Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                           cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                           min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db, disable_theano=False):\n",
    "    \"\"\"Physical model for rain-dependent autoconversion given a set of parameters and input data.\n",
    "\n",
    "    Arguments:\n",
    "    a_db, b, ard_db, brdc, brdr3, brdr0 - Power law parameters.\n",
    "    mean_mc_db, mean_mr_db - Mean masses of cloud and rain, respectively.\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "    disable_theano (optional) - Disable theano and work directly with floats. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    A Theano variable representing a 2D array where the first dimension is the dimension of any\n",
    "    vector input variables, and the second dimension is 3 (for outputting M3, cloud M0, and rain M0 rates,\n",
    "    in that order). If all inputs are scalar, the variable will be 1D. Note that the `eval` method\n",
    "    of a Theano variable can be used to produce floating-point output, assuming that necessary\n",
    "    values are provided to fully evaluate the expression defining the variable.\n",
    "\n",
    "    If disable_theano is True, cm0_db must be a 1D array, and a float will be input assuming that\n",
    "    all inputs are floats or ndarrays.\n",
    "    \"\"\"\n",
    "    # Rates from physical model\n",
    "    rate_m3_model = rain_dependent_auto_power_law(a_db, b, ard_db, brdc, brdr3, brdr0,\n",
    "                                                  cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                                  disable_theano=disable_theano)\n",
    "    rate_cm0_model = rate_m3_model - mean_mc_db\n",
    "    rate_rm0_model = rate_m3_model - mean_mr_db\n",
    "    if disable_theano:\n",
    "        output = np.zeros((len(cm0_db), 3))\n",
    "        output[:,0] = np.maximum(rate_m3_model, min_m3_auto_db)\n",
    "        output[:,1] = np.maximum(rate_cm0_model, min_cm0_auto_db)\n",
    "        output[:,2] = np.maximum(rate_rm0_model, min_rm0_auto_db)\n",
    "        return output\n",
    "    else:\n",
    "        # Limit physical model outputs.\n",
    "        rate_m3_model = tt.maximum(rate_m3_model, min_m3_auto_db)\n",
    "        rate_cm0_model = tt.maximum(rate_cm0_model, min_cm0_auto_db)\n",
    "        rate_rm0_model = tt.maximum(rate_rm0_model, min_rm0_auto_db)\n",
    "        return tt.stack((rate_m3_model, rate_cm0_model, rate_rm0_model), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5bfa7",
   "metadata": {},
   "source": [
    "Physical model setup within PyMC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc38e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:29.536875Z",
     "start_time": "2022-01-13T20:59:29.528853Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_physical_model_bin(cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                              min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db, testvals=None):\n",
    "    \"\"\"Define physical model predicting autoconversion rate as a power law in two cloud moments.\n",
    "\n",
    "    Arguments:\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "    testvals (optional) - Starting points for MCMC integration, passed to define_priors_kk.\n",
    "\n",
    "    Returns:\n",
    "    A 2D array with rows containing M3, cloud M0, and rain M0 rates, respectively.\n",
    "    \"\"\"\n",
    "    # Define physical model parameters\n",
    "    a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db = define_priors_bin(testvals)\n",
    "    # Rates from physical model\n",
    "    return run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                                  cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                  min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66edd2",
   "metadata": {},
   "source": [
    "Posterior predictive probability for uncorrelated errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6b06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:11:25.196247Z",
     "start_time": "2022-01-13T22:11:25.178853Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_uncorr_bin(idata, obs, cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                    min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations assuming uncorrelated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = -0.5 * n_obs * 3 * np.log(2. * np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            b = idata.posterior.b.data[i,j]\n",
    "            ard_db = idata.posterior.ard_db.data[i,j]\n",
    "            brdc = idata.posterior.brdc.data[i,j]\n",
    "            brdr3 = idata.posterior.brdr3.data[i,j]\n",
    "            brdr0 = idata.posterior.brdr0.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                                           cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                           min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db,\n",
    "                                           disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            sum_sq_err = np.sum((obs - rates)**2, axis=0)\n",
    "            sigmas = np.zeros((3,))\n",
    "            sigmas[0] = idata.posterior.sigma_m3.data[i,j]\n",
    "            sigmas[1] = idata.posterior.sigma_cm0.data[i,j]\n",
    "            sigmas[2] = idata.posterior.sigma_rm0.data[i,j]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + \\\n",
    "                np.sum(-0.5 * sum_sq_err / sigmas**2 - n_obs * np.log(sigmas))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ead12a",
   "metadata": {},
   "source": [
    "Alternative posterior predictive probability density calculation based on conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca735f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:11:28.991426Z",
     "start_time": "2022-01-13T22:11:28.972723Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_uncorr_conjp_bin(idata, n_obs_orig, obs, cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                          min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations assuming uncorrelated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    n_obs_orig - Number of observations used to create original data set (may be vector or scalar).\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Allow n_obs_orig to be a scalar by casting it to a vector here if necessary.\n",
    "    if np.isscalar(n_obs_orig):\n",
    "        n_obs_orig = np.repeat(n_obs_orig, 3)\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = np.sum(gammaln(0.5*(n_obs_orig+n_obs))\n",
    "                            -gammaln(0.5*(n_obs_orig))\n",
    "                            -0.5*n_obs*np.log(np.pi))\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            b = idata.posterior.b.data[i,j]\n",
    "            ard_db = idata.posterior.ard_db.data[i,j]\n",
    "            brdc = idata.posterior.brdc.data[i,j]\n",
    "            brdr3 = idata.posterior.brdr3.data[i,j]\n",
    "            brdr0 = idata.posterior.brdr0.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                                           cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                           min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db,\n",
    "                                           disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            sum_sq_err = np.sum((obs - rates)**2, axis=0)\n",
    "            sum_sq_err_orig = np.zeros((3,))\n",
    "            sum_sq_err_orig[0] = idata.posterior.sum_sq_err_m3.data[i,j]\n",
    "            sum_sq_err_orig[1] = idata.posterior.sum_sq_err_cm0.data[i,j]\n",
    "            sum_sq_err_orig[2] = idata.posterior.sum_sq_err_rm0.data[i,j]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + 0.5 * \\\n",
    "                np.sum(n_obs_orig * np.log(sum_sq_err_orig) -\n",
    "                       (n_obs_orig+n_obs)*np.log(sum_sq_err_orig + sum_sq_err))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4510d6",
   "metadata": {},
   "source": [
    "Posterior predictive probability for correlated errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7d202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:08:09.918140Z",
     "start_time": "2022-01-13T23:08:09.899602Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_corr_bin(idata, obs, cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                  min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations with correlated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = -0.5 * n_obs * 3 * np.log(2. * np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            b = idata.posterior.b.data[i,j]\n",
    "            ard_db = idata.posterior.ard_db.data[i,j]\n",
    "            brdc = idata.posterior.brdc.data[i,j]\n",
    "            brdr3 = idata.posterior.brdr3.data[i,j]\n",
    "            brdr0 = idata.posterior.brdr0.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                                           cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                           min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db,\n",
    "                                           disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            error = obs - rates\n",
    "            sum_sq_err = np.matmul(error.T, error)\n",
    "            omega = idata.posterior.omega.data[i,j,:,:]\n",
    "            log_pppd_sample[i,j] = prob_prefactor - \\\n",
    "                0.5 * np.trace(np.matmul(sum_sq_err, omega)) + \\\n",
    "                0.5 * n_obs * np.log(la.det(omega))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c6d6b",
   "metadata": {},
   "source": [
    "Alternative posterior predictive probability density calculation based on conjugate prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94986b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:08:11.161151Z",
     "start_time": "2022-01-13T23:08:11.143829Z"
    }
   },
   "outputs": [],
   "source": [
    "def posterior_predictive_corr_conjp_bin(idata, n_obs_orig, obs, cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                        min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db):\n",
    "    \"\"\"Calculate log posterior predictive probability of a set of observations with correlated errors.\n",
    "\n",
    "    Arguments:\n",
    "    idata - InferenceData object containing a trace with samples of model parameters.\n",
    "    n_obs_orig - Number of observations used to create original data set.\n",
    "    obs - Observed autoconversion rates in decibels.\n",
    "    cm0_db - 0th moment of cloud (#/kg) in decibels.\n",
    "    cm3_db - 3rd moment of cloud (m^3/kg) in decibels.\n",
    "    rm0_db, rm3_db - 0th and 3rd moments of rain.\n",
    "    rain_mask - Mask for presence of rain.\n",
    "    min_m3_auto_db - Minimum value of 3rd moment autoconversion rate that can be predicted.\n",
    "    min_cm0_auto_db - Minimum value of cloud 0th moment rate.\n",
    "    min_rm0_auto_db - Minimum value of rain 0th moment rate.\n",
    "\n",
    "    Returns:\n",
    "    The log of the posterior predictive probability density of the observations.\n",
    "    \"\"\"\n",
    "    n_obs = obs.shape[0]\n",
    "    # Prefactor contains normalization constant that's the same across samples.\n",
    "    prob_prefactor = multigammaln(3, 0.5*(n_obs + n_obs_orig)) - \\\n",
    "        multigammaln(3, 0.5*(n_obs_orig)) - 0.5 * n_obs * 3 * np.log(np.pi)\n",
    "    chain = len(idata.posterior.chain)\n",
    "    draw = len(idata.posterior.draw)\n",
    "    log_pppd_sample = np.zeros((chain, draw))\n",
    "    # Loop over samples\n",
    "    for i in range(chain):\n",
    "        for j in range(draw):\n",
    "            # Parameter values\n",
    "            a_db = idata.posterior.a_db.data[i,j]\n",
    "            b = idata.posterior.b.data[i,j]\n",
    "            ard_db = idata.posterior.ard_db.data[i,j]\n",
    "            brdc = idata.posterior.brdc.data[i,j]\n",
    "            brdr3 = idata.posterior.brdr3.data[i,j]\n",
    "            brdr0 = idata.posterior.brdr0.data[i,j]\n",
    "            mean_mc_db = idata.posterior.mean_mc_db.data[i,j]\n",
    "            mean_mr_db = idata.posterior.mean_mr_db.data[i,j]\n",
    "            # Physical model prediction\n",
    "            rates = run_physical_model_bin(a_db, b, ard_db, brdc, brdr3, brdr0, mean_mc_db, mean_mr_db,\n",
    "                                           cm0_db, cm3_db, rm0_db, rm3_db, rain_mask,\n",
    "                                           min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db,\n",
    "                                           disable_theano=True)\n",
    "            # Calculate log posterior predictive probability density for this sample\n",
    "            error = obs - rates\n",
    "            sum_sq_err = np.matmul(error.T, error)\n",
    "            sum_sq_err_orig = idata.posterior.sum_sq_err.data[i,j,:,:]\n",
    "            log_pppd_sample[i,j] = prob_prefactor + \\\n",
    "                0.5 * n_obs_orig * np.log(la.det(sum_sq_err_orig)) - \\\n",
    "                0.5 * (n_obs_orig+n_obs)*np.log(la.det(sum_sq_err_orig + sum_sq_err))\n",
    "    # Return average over samples.\n",
    "    return log_mean_exp(log_pppd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424f092",
   "metadata": {},
   "source": [
    "## Mock observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d26e3",
   "metadata": {},
   "source": [
    "Show the total number of data points from input data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2e5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:30.063300Z",
     "start_time": "2022-01-13T20:59:30.057919Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size = len(cm0_mask_pe)\n",
    "print(data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbbcd1",
   "metadata": {},
   "source": [
    "We filter out the data points where there's too little cloud present to get a slightly smaller data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8de48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:30.396761Z",
     "start_time": "2022-01-13T20:59:30.389266Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_mask = np.logical_and(cm0_mask_pe, cm3_mask_pe)\n",
    "np.count_nonzero(draw_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3a36f",
   "metadata": {},
   "source": [
    "Filtering out points where there's too little rain present gives us a different subset, which in this dataset is a strict subset of points where cloud is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bd837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:30.768766Z",
     "start_time": "2022-01-13T20:59:30.761804Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_mask_full = np.logical_and(rm0_mask_pe, rm3_mask_pe)\n",
    "print(np.count_nonzero(rain_mask_full))\n",
    "print(np.count_nonzero(np.logical_and(draw_mask, rain_mask_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f645063",
   "metadata": {},
   "source": [
    "Set up random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79904de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:31.115714Z",
     "start_time": "2022-01-13T20:59:31.110891Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=RANDOM_SEED_BIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d9f85",
   "metadata": {},
   "source": [
    "Fairly simple way of sampling data points.\n",
    "\n",
    "If values are cached, skip the sampling and read in from file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b0a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:31.672842Z",
     "start_time": "2022-01-13T20:59:31.472273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number concentration of cloud in #/kg\n",
    "cm0_fit = np.zeros((NFIT_BIN,))\n",
    "# Third moment concentration of cloud in m^3/kg\n",
    "cm3_fit = np.zeros((NFIT_BIN,))\n",
    "# Same variables for rain\n",
    "rm0_fit = np.zeros((NFIT_BIN,))\n",
    "rm3_fit = np.zeros((NFIT_BIN,))\n",
    "# Autoconversion moment rates in (m^n/kg/s)\n",
    "# Listed in the order M3, cloud M0, rain M0.\n",
    "auto_fit = np.zeros((NFIT_BIN, 3))\n",
    "\n",
    "# Same variables, evaluation set\n",
    "cm0_eval = np.zeros((NEVAL_BIN,))\n",
    "cm3_eval = np.zeros((NEVAL_BIN,))\n",
    "rm0_eval = np.zeros((NEVAL_BIN,))\n",
    "rm3_eval = np.zeros((NEVAL_BIN,))\n",
    "auto_eval = np.zeros((NEVAL_BIN, 3))\n",
    "\n",
    "file_name = 'bin_draws{}.nc'.format(SUFFIX)\n",
    "file_name = os.path.join(IDATA_DIR, file_name)\n",
    "if USE_CACHED_IDATA and os.path.isfile(file_name):\n",
    "    # Read data if cached.\n",
    "    with nc4.Dataset(file_name, 'r') as ncfile:\n",
    "        assert len(ncfile.dimensions['nfit']) == NFIT_BIN, \\\n",
    "            \"existing data file has wrong number of fit draws\"\n",
    "        assert len(ncfile.dimensions['neval']) == NEVAL_BIN, \\\n",
    "            \"existing data file has wrong number of evaluation draws\"\n",
    "        cm0_fit[:] = ncfile['cm0_fit'][:]\n",
    "        cm3_fit[:] = ncfile['cm3_fit'][:]\n",
    "        rm0_fit[:] = ncfile['rm0_fit'][:]\n",
    "        rm3_fit[:] = ncfile['rm3_fit'][:]\n",
    "        auto_fit[:,:] = ncfile['auto_fit'][:,:]\n",
    "        cm0_eval[:] = ncfile['cm0_eval'][:]\n",
    "        cm3_eval[:] = ncfile['cm3_eval'][:]\n",
    "        rm0_eval[:] = ncfile['rm0_eval'][:]\n",
    "        rm3_eval[:] = ncfile['rm3_eval'][:]\n",
    "        auto_eval[:,:] = ncfile['auto_eval'][:,:]\n",
    "else:\n",
    "    # Sample from data set.\n",
    "    num_drawn = 0\n",
    "    draws_fit = np.zeros((NFIT_BIN,), dtype='i4')\n",
    "    while num_drawn < NFIT_BIN:\n",
    "        i = rng.integers(data_size)\n",
    "        if draw_mask[i]:\n",
    "            draw_mask[i] = False\n",
    "            draws_fit[num_drawn] = i\n",
    "            cm0_fit[num_drawn] = cliqm0s_pe[i]\n",
    "            cm3_fit[num_drawn] = cliqm3s_pe[i]\n",
    "            rm0_fit[num_drawn] = rainm0s_pe[i]\n",
    "            rm3_fit[num_drawn] = rainm3s_pe[i]\n",
    "            auto_fit[num_drawn,0] = auto3s[i]\n",
    "            auto_fit[num_drawn,1] = -cauto0s[i]\n",
    "            auto_fit[num_drawn,2] = auto0s[i]\n",
    "            num_drawn += 1\n",
    "    num_drawn = 0\n",
    "    draws_eval = np.zeros((NEVAL_BIN,), dtype='i4')\n",
    "    while num_drawn < NEVAL_BIN:\n",
    "        i = rng.integers(data_size)\n",
    "        if draw_mask[i]:\n",
    "            draw_mask[i] = False\n",
    "            draws_eval[num_drawn] = i\n",
    "            cm0_eval[num_drawn] = cliqm0s_pe[i]\n",
    "            cm3_eval[num_drawn] = cliqm3s_pe[i]\n",
    "            rm0_eval[num_drawn] = rainm0s_pe[i]\n",
    "            rm3_eval[num_drawn] = rainm3s_pe[i]\n",
    "            auto_eval[num_drawn,0] = auto3s[i]\n",
    "            auto_eval[num_drawn,1] = -cauto0s[i]\n",
    "            auto_eval[num_drawn,2] = auto0s[i]\n",
    "            num_drawn += 1\n",
    "    # If writing cache, write out this sample.\n",
    "    if WRITE_CACHED_IDATA:\n",
    "        with nc4.Dataset(file_name, 'w', format='NETCDF4') as ncfile:\n",
    "            ncfile.createDimension('nfit', NFIT_BIN)\n",
    "            ncfile.createDimension('neval', NEVAL_BIN)\n",
    "            ncfile.createDimension('auto_rate', 3)\n",
    "            draws_fit_file = ncfile.createVariable('draws_fit', 'i4', ('nfit',))\n",
    "            cm3_fit_file = ncfile.createVariable('cm3_fit', 'f8', ('nfit',))\n",
    "            cm0_fit_file = ncfile.createVariable('cm0_fit', 'f8', ('nfit',))\n",
    "            rm3_fit_file = ncfile.createVariable('rm3_fit', 'f8', ('nfit',))\n",
    "            rm0_fit_file = ncfile.createVariable('rm0_fit', 'f8', ('nfit',))\n",
    "            auto_fit_file = ncfile.createVariable('auto_fit', 'f8', ('nfit', 'auto_rate'))\n",
    "            draws_eval_file = ncfile.createVariable('draws_eval', 'i4', ('neval',))\n",
    "            cm3_eval_file = ncfile.createVariable('cm3_eval', 'f8', ('neval',))\n",
    "            cm0_eval_file = ncfile.createVariable('cm0_eval', 'f8', ('neval',))\n",
    "            rm3_eval_file = ncfile.createVariable('rm3_eval', 'f8', ('neval',))\n",
    "            rm0_eval_file = ncfile.createVariable('rm0_eval', 'f8', ('neval',))\n",
    "            auto_eval_file = ncfile.createVariable('auto_eval', 'f8', ('neval', 'auto_rate'))\n",
    "            draws_fit_file[:] = draws_fit\n",
    "            cm0_fit_file[:] = cm0_fit\n",
    "            cm3_fit_file[:] = cm3_fit\n",
    "            rm0_fit_file[:] = rm0_fit\n",
    "            rm3_fit_file[:] = rm3_fit\n",
    "            auto_fit_file[:,:] = auto_fit[:,:]\n",
    "            draws_eval_file[:] = draws_eval\n",
    "            cm0_eval_file[:] = cm0_eval\n",
    "            cm3_eval_file[:] = cm3_eval\n",
    "            rm0_eval_file[:] = rm0_eval\n",
    "            rm3_eval_file[:] = rm3_eval\n",
    "            auto_eval_file[:,:] = auto_eval[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebf23b",
   "metadata": {},
   "source": [
    "Rain masks for sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9afb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:31.844323Z",
     "start_time": "2022-01-13T20:59:31.838189Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_mask_fit = np.logical_and(rm0_fit > 1.e-2, rm3_fit > 1.e-15 / (np.pi / 6. * rhow))\n",
    "rain_mask_eval = np.logical_and(rm0_eval > 1.e-2, rm3_eval > 1.e-15 / (np.pi / 6. * rhow))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15746548",
   "metadata": {},
   "source": [
    "Calculate limiters and apply them to autoconversion data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc1459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:32.189391Z",
     "start_time": "2022-01-13T20:59:32.175785Z"
    }
   },
   "outputs": [],
   "source": [
    "min_m3_auto = auto3s.max() * MIN_OBS_FAC\n",
    "min_cm0_auto = -cauto0s.min() * MIN_OBS_FAC # cauto0s is negative, but corresponding auto entry is positive.\n",
    "min_rm0_auto = auto0s.max() * MIN_OBS_FAC\n",
    "min_m3_auto_db = 10. * np.log10(min_m3_auto)\n",
    "min_cm0_auto_db = 10. * np.log10(min_cm0_auto)\n",
    "min_rm0_auto_db = 10. * np.log10(min_rm0_auto)\n",
    "auto_fit_obslim = np.zeros((NFIT_BIN, 3))\n",
    "auto_fit_obslim[:,0] = np.maximum(auto_fit[:,0], min_m3_auto)\n",
    "auto_fit_obslim[:,1] = np.maximum(auto_fit[:,1], min_cm0_auto)\n",
    "auto_fit_obslim[:,2] = np.maximum(auto_fit[:,2], min_rm0_auto)\n",
    "auto_eval_obslim = np.zeros((NEVAL_BIN, 3))\n",
    "auto_eval_obslim[:,0] = np.maximum(auto_eval[:,0], min_m3_auto)\n",
    "auto_eval_obslim[:,1] = np.maximum(auto_eval[:,1], min_cm0_auto)\n",
    "auto_eval_obslim[:,2] = np.maximum(auto_eval[:,2], min_rm0_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bf353",
   "metadata": {},
   "source": [
    "Convert sampled data to decibels. Since there can be zero or near-zero values for the rain moments, set values filtered by the rain masks to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fcbb96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:32.581845Z",
     "start_time": "2022-01-13T20:59:32.559532Z"
    }
   },
   "outputs": [],
   "source": [
    "cm0_fit_db = 10. * np.log10(cm0_fit)\n",
    "cm3_fit_db = 10. * np.log10(cm3_fit)\n",
    "rm0_fit_db = 10. * np.log10(np.where(rain_mask_fit, rm0_fit, 1.))\n",
    "rm3_fit_db = 10. * np.log10(np.where(rain_mask_fit, rm3_fit, 1.))\n",
    "bin_auto_fit_db = 10. * np.log10(auto_fit_obslim)\n",
    "cm0_eval_db = 10. * np.log10(cm0_eval)\n",
    "cm3_eval_db = 10. * np.log10(cm3_eval)\n",
    "rm0_eval_db = 10. * np.log10(np.where(rain_mask_eval, rm0_eval, 1.))\n",
    "rm3_eval_db = 10. * np.log10(np.where(rain_mask_eval, rm3_eval, 1.))\n",
    "bin_auto_eval_db = 10. * np.log10(auto_eval_obslim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f452c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:32.744842Z",
     "start_time": "2022-01-13T20:59:32.739747Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_kwargs_bin = {\n",
    "    'cm0_db': cm0_fit_db,\n",
    "    'cm3_db': cm3_fit_db,\n",
    "    'rm0_db': rm0_fit_db,\n",
    "    'rm3_db': rm3_fit_db,\n",
    "    'rain_mask': rain_mask_fit,\n",
    "    'min_m3_auto_db': min_m3_auto_db,\n",
    "    'min_cm0_auto_db': min_cm0_auto_db,\n",
    "    'min_rm0_auto_db': min_rm0_auto_db,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350b2b",
   "metadata": {},
   "source": [
    "## Uncorrelated errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7df4d",
   "metadata": {},
   "source": [
    "List of parameters for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09e3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:33.786401Z",
     "start_time": "2022-01-13T20:59:33.781690Z"
    }
   },
   "outputs": [],
   "source": [
    "uncorr_parameters_bin = ['a_db', 'b', 'ard_db', 'brdc', 'brdr3', 'brdr0', 'mean_mc_db', 'mean_mr_db',\n",
    "                         'sigma_m3', 'sigma_cm0', 'sigma_rm0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99df71c",
   "metadata": {},
   "source": [
    "Define variable names to use for names of error parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f897266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T20:59:34.577973Z",
     "start_time": "2022-01-13T20:59:34.573049Z"
    }
   },
   "outputs": [],
   "source": [
    "var_names = ['m3', 'cm0', 'rm0']\n",
    "error_kwargs_uncorr_bin = {\n",
    "    'var_names': var_names,\n",
    "}\n",
    "post_kwargs_uncorr_bin = {\n",
    "    'var_names': var_names,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5d7c4",
   "metadata": {},
   "source": [
    "### With explicit sigma parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdc715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:07:34.711735Z",
     "start_time": "2022-01-13T22:01:34.716737Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_uncorr = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_uncorrelated_error_multiple,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_uncorr_bin,\n",
    "        file_prefix='bin_idata_uncorr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb391ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:07:35.308176Z",
     "start_time": "2022-01-13T22:07:34.713986Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_uncorr, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f134bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:07:39.650826Z",
     "start_time": "2022-01-13T22:07:35.309469Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_uncorr, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:07:44.439057Z",
     "start_time": "2022-01-13T22:07:39.653095Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_uncorr, uncorr_parameters_bin, kind='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfec908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:57:58.395589Z",
     "start_time": "2022-01-13T22:53:39.078745Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_bin(bin_idata_uncorr, bin_auto_eval_db,\n",
    "                                cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                                min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a7259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T05:08:39.075353Z",
     "start_time": "2022-01-13T23:13:39.410683Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_nuts95_uncorr = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_uncorrelated_error_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_uncorr_bin,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        file_prefix='bin_idata_nuts95_uncorr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80d66a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T05:08:39.598351Z",
     "start_time": "2022-01-14T05:08:39.080095Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_nuts95_uncorr, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a7d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T05:08:44.648027Z",
     "start_time": "2022-01-14T05:08:39.600067Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_nuts95_uncorr, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d2648",
   "metadata": {},
   "source": [
    "### With conjugate prior method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123b040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:30:17.502227Z",
     "start_time": "2022-01-13T22:21:03.273873Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_uncorr_conjp = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_uncorrelated_error_conjp_multiple,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        post_mcmc_sample=add_sigma_samples_multiple,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_uncorr_bin,\n",
    "        post_kwargs=post_kwargs_uncorr_bin,\n",
    "        file_prefix='bin_idata_uncorr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f870f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:30:18.233299Z",
     "start_time": "2022-01-13T22:30:17.504603Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_uncorr_conjp, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039cd0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:30:24.125750Z",
     "start_time": "2022-01-13T22:30:18.234604Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_uncorr_conjp, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14a755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:02:14.420287Z",
     "start_time": "2022-01-13T22:57:58.397994Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_bin(bin_idata_uncorr_conjp, bin_auto_eval_db,\n",
    "                                cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                                min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef100820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:06:29.668205Z",
     "start_time": "2022-01-13T23:02:14.424099Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_uncorr_conjp_bin(bin_idata_uncorr_conjp, NFIT_BIN, bin_auto_eval_db,\n",
    "                                      cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                                      min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d9080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:32:57.852269Z",
     "start_time": "2022-01-14T05:08:44.650368Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_nuts95_uncorr_conjp = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_uncorrelated_error_conjp_multiple,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_sigma_samples_multiple,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_uncorr_bin,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        post_kwargs=post_kwargs_uncorr_bin,\n",
    "        file_prefix='bin_idata_nuts95_uncorr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92f87c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:32:58.430783Z",
     "start_time": "2022-01-14T10:32:57.857151Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_nuts95_uncorr_conjp, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0fa3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:33:03.560206Z",
     "start_time": "2022-01-14T10:32:58.432672Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_nuts95_uncorr_conjp, uncorr_parameters_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4410b71",
   "metadata": {},
   "source": [
    "## Correlated errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb195e7f",
   "metadata": {},
   "source": [
    "List of parameters for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6fcc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:43:10.273228Z",
     "start_time": "2022-01-13T22:43:10.269982Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_parameters_bin = ['a_db', 'b', 'ard_db', 'brdc', 'brdr3', 'brdr0', 'mean_mc_db', 'mean_mr_db',\n",
    "                       'omega_chol_elems']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305c69",
   "metadata": {},
   "source": [
    "### With explicit precision matrix entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb393a8b",
   "metadata": {},
   "source": [
    "Dictionary of names needed by the error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98565e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:44:31.076466Z",
     "start_time": "2022-01-13T22:44:31.071892Z"
    }
   },
   "outputs": [],
   "source": [
    "error_kwargs_corr_bin = {\n",
    "    'name': 'rates',\n",
    "    'omega_name': 'omega',\n",
    "    'omega_chol_name': 'omega_chol_elems'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abbacb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:51:05.919557Z",
     "start_time": "2022-01-13T22:45:32.029712Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_corr = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_corr_bin,\n",
    "        file_prefix='bin_idata_corr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8dfb8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:51:07.349983Z",
     "start_time": "2022-01-13T22:51:05.924173Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_corr, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0e33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:51:13.099314Z",
     "start_time": "2022-01-13T22:51:07.352233Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_corr, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8494c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:21.052952Z",
     "start_time": "2022-01-13T23:08:17.938801Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_bin(bin_idata_corr, bin_auto_eval_db,\n",
    "                              cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                              min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998acb0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:36:32.665Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_nuts95_corr = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_correlated_error,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_corr_bin,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        file_prefix='bin_idata_nuts95_corr',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b91478",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:36:52.457Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_nuts95_corr, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44c80f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:37:21.130Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_nuts95_corr, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc205d30",
   "metadata": {},
   "source": [
    "### With conjugate prior method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba5340",
   "metadata": {},
   "source": [
    "Dictionary of values needed by error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad3aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:51:13.105164Z",
     "start_time": "2022-01-13T22:51:13.101753Z"
    }
   },
   "outputs": [],
   "source": [
    "error_kwargs_corr_conjp_bin = {\n",
    "    'output_name': 'log_like',\n",
    "    'sum_sq_err_name': 'sum_sq_err',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c7761",
   "metadata": {},
   "source": [
    "Dictionary of values needed by post-MCMC sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447954e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:51:13.119274Z",
     "start_time": "2022-01-13T22:51:13.106371Z"
    }
   },
   "outputs": [],
   "source": [
    "post_kwargs_corr_bin = {\n",
    "    'sum_sq_err_name': 'sum_sq_err',\n",
    "    'omega_name': 'omega',\n",
    "    'omega_chol_name': 'omega_chol_elems',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e83f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:21.101176Z",
     "start_time": "2022-01-13T23:12:21.056290Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_corr_conjp = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_metropolis,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_corr_conjp_bin,\n",
    "        post_kwargs=post_kwargs_corr_bin,\n",
    "        file_prefix='bin_idata_corr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06149be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:21.234185Z",
     "start_time": "2022-01-13T23:12:21.102911Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_corr_conjp, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f5be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:25.172694Z",
     "start_time": "2022-01-13T23:12:21.236165Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_corr_conjp, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11336532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:35.021040Z",
     "start_time": "2022-01-13T23:12:25.174635Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_bin(bin_idata_corr_conjp, bin_auto_eval_db,\n",
    "                              cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                              min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99165d74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T23:12:44.927381Z",
     "start_time": "2022-01-13T23:12:35.022619Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_corr_conjp_bin(bin_idata_corr_conjp, NFIT_BIN, bin_auto_eval_db,\n",
    "                                    cm0_eval_db, cm3_eval_db, rm0_eval_db, rm3_eval_db, rain_mask_eval,\n",
    "                                    min_m3_auto_db, min_cm0_auto_db, min_rm0_auto_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18814728",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:38:17.122Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    bin_idata_nuts95_corr_conjp = run_mcmc(\n",
    "        obs=bin_auto_fit_db,\n",
    "        physical_model=define_physical_model_bin,\n",
    "        error_model=define_correlated_error_conjp,\n",
    "        mcmc_sample=sample_NUTS,\n",
    "        post_mcmc_sample=add_omega_samples,\n",
    "        physical_kwargs=physical_kwargs_bin,\n",
    "        error_kwargs=error_kwargs_corr_conjp_bin,\n",
    "        mcmc_kwargs={'target_accept': 0.95},\n",
    "        post_kwargs=post_kwargs_corr_bin,\n",
    "        file_prefix='bin_idata_nuts95_corr_conjp',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4f24e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:38:41.277Z"
    }
   },
   "outputs": [],
   "source": [
    "print_summary_statistics(bin_idata_nuts95_corr_conjp, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25603b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T23:39:11.988Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trace(bin_idata_nuts95_corr_conjp, corr_parameters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0210958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
